{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503132fc",
   "metadata": {},
   "source": [
    "# Processamento Digital de Imagens - Trabalho Prático 2\n",
    "\n",
    "## 1. Introdução e Preparação\n",
    "\n",
    "<p>O principal objetivo deste trabalho é <b>aplicação</b> de técnicas, embora envolva implementação também. Porém, boa parte das técnicas que necessitarão encontra-se exemplificada em algoritmos nos slides, com implementação parecida nos Notebooks disponíveis ou, às vezes, até mesmo já implementada nestes mesmos Notebooks. Portanto, o foco é no uso das técnicas, enquanto o primeiro trabalho tinha seu foco mais em implementação. Embora, mais uma vez, em ambos trabalhos estão envolvidos ambos aspectos: implementação e aplicação.</p>\n",
    "\n",
    "### a) Edite a célula abaixo, preencha com seus dados pessoais e a execute novamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915a930",
   "metadata": {},
   "source": [
    "- Aluno(a)\n",
    "\n",
    "    - Nome: gabriel macedo nunes pontes\n",
    "    - Matrícula: 98877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd30484",
   "metadata": {},
   "source": [
    "### b) Observações e instruções gerais (não são exatamente as mesmas do trabalho anterior, releia):\n",
    "\n",
    "- Entregue <b>apenas</b> o notebook resultante do seu trabalho, <b>mesmo que tenha sido feito usando o Google Colab</b>. Não há necessidade de se entregar qualquer outro arquivo.\n",
    "- O trabalho deve ser desenvolvido <b>inidivualmente</b> pelos alunos da UFV (Viçosa e Rio Paranaíba). Os alunos de <b>outras instituições e áreas</b> (e apenas estes), podem desenvolver em duplas.\n",
    "- O trabalho é composto por várias tarefas individuais, que não são necessariamente conectadas umas às outras. Cada tarefa tem seu próprio enunciado.\n",
    "- <u>A menos que seja informado o contrário no exercício</u>, está <b>vetado</b> o uso de recursos e implementações prontas dos recursos pedidos nas tarefas deste trabalho. Você deve implementar o recurso.\n",
    "    - Exemplo 1: se pedido, como alvo da tarefa, que você implemente/faça a conversão de cinza de uma imagem, você não pode usar a conversão que vem pronta na biblioteca PIl.\n",
    "    - Exemplo 2: se um passo secundário de um algoritmo maior demanda a conversão em cinza de uma imagem, mas não é o foco do exercício, você pode usar a conversão pronta da biblioteca PIL.\n",
    "    - <font color=\"red\">Exceção: </font> para operações morfológicas sobre imagens binárias, <u>caso você opte por usá-las</u> (não é nada obrigatório), está liberado o uso de funções prontas da biblioteca <i>OpenCV</i>\n",
    "- Está <b>liberado</b> o uso de outras bibliotecas que desejar incluir, em especial, as não diretamente relacionadas ao conteúdo de PDI.\n",
    "- Os exemplos mostrado ao longo deste Notebook estão na subpasta <code>imagens/exemplos/</code>. Você pode abri-las separadamente, para analisar em mais detalhes, se desejar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66038513",
   "metadata": {},
   "source": [
    "### c) Execute a célula abaixo, que conterá as importações de módulos Python.\n",
    "\n",
    "#### Você é livre para (<font color=\"red\">e provavelmente precisará</font>) editar e adicionar outras importações a esta célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotagem de gráficos e imagens no notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Manipulação de imagens\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from scipy.interpolate import interp2d\n",
    "import numpy as np # Manipulação de arrays\n",
    "import os # Acesso ao sistema de arquivos do SO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c500fd",
   "metadata": {},
   "source": [
    "### d) Funções auxiliares prontas. Execute as células a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310fe681",
   "metadata": {},
   "source": [
    "<p>Função <code>exibe_bloco</code>:</p>\n",
    "\n",
    "- Exibe, em tela, diversas imagens, em um grid\n",
    "- <u>Parâmetros de entrada:</u>\n",
    "    - <code>imgs</code>: lista <i>Python</i> contendo $n > 1$ objetos <code>PIL Image</code>, a serem exibidos em tela\n",
    "    - <code>titulos</code>: lista <i>Python</i> contendo $n$ strings, com o título de cada imagem. Opcional. Se não fornecida, gera títulos automaticamente, com 'Imagem 1', 'Imagem 2' etc.\n",
    "    - <code>tam_linha</code>: valor inteiro, informando quantas imagens por linha serão exibidas. Opcional. Valor <i>default</i>: 4\n",
    "    - <code>arquivo</code>: string que, se fornecida, habilita o salvamento da visualização das imagens em um arquivo em memória secundária, usando o nome de arquivo fornecido no parâmetro. Opcional. <i>Default:</i> <code>None</code>\n",
    "    - <code>dpi</code>: <i>float</i> que, se fornecido, determina a resolução da imagem gerada. Opcional. <i>Default</i>: $100$\n",
    "    - Gera erro se os comprimentos de <code>imgs</code> e <code>titulos</code> não forem os mesmos ou se <code>len(imgs)</code> $< 2$.\n",
    "- <u>Retorno:</u> nenhum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibe_bloco(imgs, titulos=None, tam_linha=4, arquivo=None, dpi=100):\n",
    "    assert len(imgs) > 1\n",
    "    \n",
    "    # Espaçamento entre imagens (em pixels)\n",
    "    espacamento_x = 15\n",
    "    espacamento_y = 20\n",
    "    \n",
    "    # Calcula o número de linhas\n",
    "    if len(imgs) < tam_linha:\n",
    "        tam_linha = len(imgs)\n",
    "    nlinhas = len(imgs) // tam_linha + int(len(imgs) % tam_linha > 0)\n",
    "    \n",
    "    # Cria lista de arrays e calcula tamanho da imagem de visualização a ser exibida/salva\n",
    "    largura_px = 0\n",
    "    altura_px = 0\n",
    "    i = 0\n",
    "    imagens = []\n",
    "    for img in imgs:\n",
    "        if img.mode == 'L':\n",
    "            img = img.convert('RGB')\n",
    "        imagens.append(np.asarray(img))\n",
    "        if i % tam_linha == 0:\n",
    "            max_altura_linha = 0\n",
    "            largura_linha = 0\n",
    "        largura_linha += img.width\n",
    "        if img.height > max_altura_linha:\n",
    "            max_altura_linha = img.height\n",
    "        if i % tam_linha == tam_linha-1 or i == len(imgs)-1:\n",
    "            altura_px += max_altura_linha\n",
    "            if largura_linha > largura_px:\n",
    "                largura_px = largura_linha\n",
    "        i += 1        \n",
    "    largura_px += (tam_linha-1)*espacamento_x\n",
    "    altura_px += (nlinhas-1)*espacamento_y\n",
    "    largura_inch = largura_px / float(dpi)\n",
    "    altura_inch = altura_px / float(dpi)\n",
    "    \n",
    "    # Cria lista de títulos\n",
    "    if titulos is None:\n",
    "        titulos = []\n",
    "        for i in range(len(imagens)):\n",
    "            titulos.append('Imagem %d' % (i+1))\n",
    "    else:\n",
    "        assert len(imgs) == len(titulos)\n",
    "    \n",
    "    # Plota imagens em grid\n",
    "    plt.rcParams['figure.figsize'] = [largura_inch,altura_inch]\n",
    "    fig, axes = plt.subplots(nrows=nlinhas, ncols=tam_linha)\n",
    "    for i,ax in enumerate(axes.ravel()):\n",
    "        ax.axis('off')\n",
    "        if i < len(imgs):\n",
    "            ax.imshow(imagens[i])\n",
    "            ax.set_title(titulos[i])\n",
    "        else:\n",
    "            fig.delaxes(ax)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Salva, se desejado\n",
    "    if arquivo is not None:\n",
    "        plt.savefig(arquivo, dpi=dpi)\n",
    "        print('Visualização salva em %s.' % arquivo)\n",
    "        \n",
    "    # Exibe\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2776a",
   "metadata": {},
   "source": [
    "<p>Função <code>getArrayCinza</code>:</p>\n",
    "\n",
    "- Retorna um array <code>numpy</code> contendo as informações da versão em tons de cinza de uma imagem\n",
    "- Se a entrada for uma imagem colorida, faz a conversão para tons de cinza antes de extrair o array, ou, se a entrada já for monocromática, apenas extrai e retorna o array\n",
    "- <u>Parâmetro de entrada:</u> <code>img</code>: objeto <code>PIL Image</code>\n",
    "- <u>Retorno:</u> array <code>numpy</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37218d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArrayCinza(img):\n",
    "    if img.mode == 'L':\n",
    "        arr = np.asarray(img).copy()\n",
    "    else:\n",
    "        arr = np.asarray(img.convert('L')).copy()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53be2c",
   "metadata": {},
   "source": [
    "## 2. Recuperação de informações em imagens de baixa qualidade\n",
    "\n",
    "<p>Para todos exercícios desta parte, você é livre para usar <b>quaisquer</b> conhecimentos vistos na disciplina e pode/deve combinar técnicas à vontade.</p>\n",
    "\n",
    "<p><b>Obs.:</b> diferentemente do primeiro trabalho, desta vez as imagens são apenas um guia ilustrativo, uma referência à qual você deve se aproximar o máximo que conseguir. No entanto, poderão ser consideradas como \"corretas\", respostas que se difiram dos exemplos ilustrados em cada item.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5318e6",
   "metadata": {},
   "source": [
    "### 2.1 Tornando textos mais legíveis\n",
    "\n",
    "<p>Na subpasta <code>imagens</code> encontram-se três fotos de textos impressos em papel, obtidas sob más condições de iluminação ou de sombra e uma imagem \"sintética\", de um texto em formato digital sobre o qual foi inserida uma sombra artificialmente. São os arquivos:</p>\n",
    "\n",
    "- <code>texto_1.jpg</code>\n",
    "- <code>texto_2.jpg</code>\n",
    "- <code>texto_sombra.jpg</code>\n",
    "- <code>texto_sombra_sintetico.jpg</code>\n",
    "\n",
    "<p>Copie e cole a implementação do algoritmo de Otsu dado em aula e binarize as imagens com a função, para ver os resultados. Responda na célula abaixo: o que aconteceu com o resultado? Ele é útil, na prática? Por que você acha que aconteceu este fenômeno?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(f, L):\n",
    "    h = np.zeros(L)\n",
    "    \n",
    "    for k in range(L):\n",
    "        h[k] = np.sum(f == k)\n",
    "    \n",
    "    # O laço acima equivale a:\n",
    "    #for y in range(f.shape[0]):\n",
    "    #    for x in range(f.shape[1]):\n",
    "    #        k = int(f[y,x])\n",
    "    #        h[k] += 1\n",
    "        \n",
    "    return h\n",
    "\n",
    "def calcula_cdf(p):\n",
    "    cdf = np.zeros(p.shape)\n",
    "    \n",
    "    for k in range(len(p)):\n",
    "        cdf[k] = np.sum(p[:k+1])\n",
    "        \n",
    "    return cdf\n",
    "\n",
    "def gera_histogramas(f, L):\n",
    "    # Contagem de pixels da imagem\n",
    "    n = f.shape[0] * f.shape[1]\n",
    "    \n",
    "    h = histograma(f, L)\n",
    "    p = h / n\n",
    "    cdf = calcula_cdf(p)\n",
    "\n",
    "    return h,p,cdf\n",
    "    \n",
    "def histogramas(f, Lmax=255):\n",
    "    # Contagem do número de tons:\n",
    "    L = Lmax + 1\n",
    "    \n",
    "    # identifica o tipo de imagem\n",
    "    if len(f.shape) < 3:\n",
    "        # Imagem cinza\n",
    "        return gera_histogramas(f, L)\n",
    "    else:\n",
    "        # Imagem RGB\n",
    "        hr,pr,cdfr = gera_histogramas(f[:,:,0], L)\n",
    "        hg,pg,cdfg = gera_histogramas(f[:,:,1], L)\n",
    "        hb,pb,cdfb = gera_histogramas(f[:,:,2], L)\n",
    "        \n",
    "        return (hr,hg,hb), (pr,pg,pb), (cdfr, cdfg, cdfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu(img, verboso=False):\n",
    "    # Converte para tons de cinza, se necessário, e extrai array\n",
    "    if img.mode != 'L':\n",
    "        arr = np.asarray(img.convert('L')).copy()\n",
    "    else:\n",
    "        arr = np.asarray(img).copy()\n",
    "        \n",
    "    # Calcula histogramas\n",
    "    p = histograma(arr, 256) / (img.width * img.height)\n",
    "    cdf = calcula_cdf(p)\n",
    "    \n",
    "    # Calcula média geral\n",
    "    i = np.arange(0, 256) # Array com os valores dos tons de cinza\n",
    "    mu = np.sum(p * i)\n",
    "    \n",
    "    # Inicializa variáveis de controle\n",
    "    th = 0\n",
    "    maxVar = 0\n",
    "    \n",
    "    # Encontra o tom k que leva à máxima variância intergrupos\n",
    "    for k in range(1,255):\n",
    "        # Calcula as médias dos valores de cada grupo gerado com k como limiar\n",
    "        if cdf[k] != 0:\n",
    "            mu1 = np.sum(p[:k+1] * i[:k+1]) / cdf[k]\n",
    "        else:\n",
    "            mu1 = 0.0\n",
    "        \n",
    "        if cdf[k] != 1:\n",
    "            mu2 = np.sum(p[k+1:] * i[k+1:]) / (1 - cdf[k])\n",
    "        else:\n",
    "            mu2 = 0.0\n",
    "        \n",
    "        # Calcula a variância intergrupos\n",
    "        sigma2 = cdf[k] * (mu1 - mu)** 2 + (1 - cdf[k]) * (mu2 - mu)**2\n",
    "        \n",
    "        # Se a variância integrupos da iteração é o novo valor máximo, atualiza\n",
    "        if sigma2 > maxVar:\n",
    "            maxVar = sigma2\n",
    "            th = k\n",
    "            \n",
    "    # Aplica a binarização com o valor de tom que leva ao máximo de variância encontrado (salvo em th)\n",
    "    arr[arr <= th] = 0\n",
    "    arr[arr > th] = 255\n",
    "    \n",
    "    if verboso:\n",
    "        print('Limiar ótimo encontrado: %.4f' % th)\n",
    "    \n",
    "    return Image.fromarray(np.uint8(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1 = Image.open('imagens/texto_1.jpg')\n",
    "texto1=otsu(texto1)\n",
    "texto2 = Image.open('imagens/texto_2.jpg')\n",
    "texto2=otsu(texto2)\n",
    "textos = Image.open('imagens/texto_sombra.jpg')\n",
    "textos=otsu(textos)\n",
    "textoss = Image.open('imagens/texto_sombra_sintetico.jpg')\n",
    "textoss=otsu(textoss)\n",
    "img=[texto1,texto2,textos,textoss]\n",
    "exibe_bloco(img)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea487957",
   "metadata": {},
   "source": [
    "O resultado é bem inutil pois ele corta partes de texto inteiras,isso acontece pois partes muito escuras o algoritmo não consegue diferenciar as letras do fundo tornando tudo preto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa3fea",
   "metadata": {},
   "source": [
    "<p><font color=\"red\">Adicione, a seguir, quantas células desejar e implemente</font> códigos que melhorem a legibilidade dos textos contidos nos arquivos. Leve em conta:</p>\n",
    "\n",
    "- Pode-se aproveitar soluções já feitas por você ou que tenha usado no trabalho anterior, se desejar\n",
    "- O resultado final <b>deve</b> estar em formato \"pseudo-binário\", isto é, imagens em tons de cinza, mas contendo somente pixels com valores $0$ e $255$\n",
    "- Existem diversas maneiras de se obter resultados como os mostrados nos exemplos, portanto, conforme já dito, os exemplos são apenas para se mostrar que tipo de resultado obter\n",
    "- As soluções dadas por você podem ser específicas para cada caso, não é necessário se criar uma função que funcione para os quatro casos dados. Por exemplo:\n",
    "    - A escolha de parâmetros de algoritmos para um caso pode ser diferente da de outro\n",
    "    - A escolha do encademento/sequência de técnicas usadas para um caso pode ser diferente da de outro\n",
    "- Gere pelo menos uma solução para cada caso. Se conseguir gerar mais, melhor :-)\n",
    "\n",
    "<p>Exemplos:</p>\n",
    "\n",
    "<img src=\"imagens/exemplos/texto_1.jpg?2\" width=\"100%\">\n",
    "<img src=\"imagens/exemplos/texto_2.jpg?2\" width=\"100%\">\n",
    "<img src=\"imagens/exemplos/texto_sombra.jpg?2\" width=\"100%\">\n",
    "<img src=\"imagens/exemplos/texto_sombra_sintetico.jpg?2\" width=\"100%\">\n",
    "\n",
    "- Para produzir cada item de exemplo acima, foram utilizadas duas sequências de diferentes passos, como filtro de suavização, melhorias de contraste, limiarizações etc\n",
    "- As imagens resultados encontram-se na subpastas <code>imagens/exemplos/</code>, as quais podem ser visualizadas separadamente, com a possibilidade de zoom e outras operações que desejar, para analisar os resultados produzidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equaliza(img):\n",
    "    p = histograma(img, 256) / (img.shape[0] * img.shape[1])\n",
    "    cdf = calcula_cdf(p)*255\n",
    "    for X in range(img.shape[0]):\n",
    "        for Y in range(img.shape[1]):\n",
    "            pixel=img[X,Y]\n",
    "            pixel=cdf[pixel]\n",
    "            img[X,Y]=pixel\n",
    "    return img\n",
    "                \n",
    "def limiarVariavel(arr, t, a=0.5, b=0.5):\n",
    "    # A fazer: vetar t de valor par\n",
    "    raio = t//2\n",
    "    \n",
    "    # Array de retorno\n",
    "    arrBin = arr.copy()\n",
    "    \n",
    "    # Percorre a imagem pixel a pixel calculando os limiares locais\n",
    "    for y in range(arr.shape[0]):\n",
    "        iniVizy = max(0, y-raio)\n",
    "        fimVizy = min(y+raio, arr.shape[0]-1)\n",
    "        \n",
    "        for x in range(arr.shape[1]):\n",
    "            iniVizx = max(0, x-raio)\n",
    "            fimVizx = min(x+raio, arr.shape[1]-1)\n",
    "            \n",
    "            mu = np.mean(arr[iniVizy:fimVizy+1, iniVizx:fimVizx+1])\n",
    "            sigma = np.std(arr[iniVizy:fimVizy+1, iniVizx:fimVizx+1])\n",
    "            \n",
    "            th = a * sigma + b * mu\n",
    "            \n",
    "            if arr[y,x] <= th:\n",
    "                arrBin[y,x] = 0\n",
    "            else:\n",
    "                arrBin[y,x] = 255\n",
    "                \n",
    "    return Image.fromarray(np.uint8(arrBin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1 = Image.open('imagens/texto_1.jpg')\n",
    "texto2 = Image.open('imagens/texto_2.jpg')\n",
    "textos = Image.open('imagens/texto_sombra.jpg')\n",
    "textoss = Image.open('imagens/texto_sombra_sintetico.jpg')\n",
    "texto1=getArrayCinza(texto1)\n",
    "texto2=getArrayCinza(texto2)\n",
    "textos=getArrayCinza(textos)\n",
    "textoss=getArrayCinza(textoss)\n",
    "texto1=limiarVariavel(texto1,14)\n",
    "texto1=Image.fromarray(np.uint8(texto1))\n",
    "texto2=limiarVariavel(texto2,14)\n",
    "texto2=Image.fromarray(np.uint8(texto2))\n",
    "textos=equaliza(textos)\n",
    "textos=limiarVariavel(textos,14)\n",
    "textos=Image.fromarray(np.uint8(textos))\n",
    "textoss=limiarVariavel(textoss,14,a=0.5,b=0.9)\n",
    "textoss=Image.fromarray(np.uint8(textoss))\n",
    "exibe_bloco([texto1,texto2,textos,textoss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea06df",
   "metadata": {},
   "source": [
    "### 2.2 Recuperando informação de foto com problemas de exposição\n",
    "\n",
    "<p>Na tentativa de se obter uma foto como a da esquerda, no exemplo abaixo, usando uma câmera semiprofissional com um filtro de lente especial, cometeu-se um erro nas configurações da câmera e a imagem danificada, na direita, foi gerada. Não se trata de um exemplo simulado, mas um exemplo real de uma foto que foi adquirida com defeitos.</p>\n",
    "\n",
    "<img src=\"imagens/exemplos/copos.png\" width=\"80%\">\n",
    "\n",
    "<p>O arquivo da foto defeituosa encontra-se em <code>imagens/vermelho.png</code>.</p>\n",
    "\n",
    "<p>Mesmo com os problemas da foto defeituosa, ainda é possível se destacar, mesmo que de forma imprecisa, algumas informações de forma dos objetos principais presentes na mesma.</p>\n",
    "\n",
    "<p><font color=\"red\">Adicione, a seguir, quantas células desejar e implemente</font> códigos que visam destacar, de alguma forma os objetos principais da imagem danificada. Leve em conta:</p>\n",
    "\n",
    "- Pode-se aproveitar soluções já feitas por você ou que tenha usado no trabalho anterior, se desejar\n",
    "- O resultado final <b>pode</b> estar em formato de tons de cinza propriamente dito ou em formato \"pseudo-binário\", isto é, imagens em tons de cinza, mas contendo somente pixels com valores $0$ e $255$\n",
    "- Existem diversas maneiras de se obter resultados como os mostrados nos exemplos, portanto, conforme já dito, os exemplos são apenas para se mostrar que tipo de resultado obter\n",
    "- As soluções dadas por você podem ser específicas para cada caso, não é necessário se criar uma função que funcione para os quatro casos dados. Por exemplo:\n",
    "    - A escolha de parâmetros de algoritmos para um caso pode ser diferente da de outro\n",
    "    - A escolha do encademento/sequência de técnicas usadas para um caso pode ser diferente da de outro\n",
    "- Gere pelo menos uma solução para cada caso. Se conseguir gerar mais, melhor :-)\n",
    "\n",
    "<p>Exemplos de resultados:</p>\n",
    "\n",
    "<img src=\"imagens/exemplos/copos_destaque.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolucao_linear_impar(img, k, canais, clip=True, ret_img=True):\n",
    "    # Centro do kernel e deslocamento\n",
    "    desloc = i = j = k.shape[0] // 2\n",
    "    \n",
    "    # Cria array com padding\n",
    "    if canais > 1:\n",
    "        arr = np.zeros((img.height+2*desloc, img.width+2*desloc, canais))\n",
    "    else:\n",
    "        arr = np.zeros((img.height+2*desloc, img.width+2*desloc))\n",
    "    # Copiar dados da imagem para o \"centro\" do array com padding\n",
    "    if canais > 1:\n",
    "        arr[desloc:arr.shape[0]-desloc,desloc:arr.shape[1]-desloc,:] = np.asarray(img)\n",
    "    else:\n",
    "        arr[desloc:arr.shape[0]-desloc,desloc:arr.shape[1]-desloc] = np.asarray(img)\n",
    "    arr_orig = arr.copy()\n",
    "    \n",
    "    # Efetua convolução (tamanho ímpar, com referência no centro do kernel)\n",
    "    # Percorre apenas posições \"internas\"\n",
    "    for y in range(desloc,arr.shape[0]-desloc):\n",
    "        for x in range(desloc,arr.shape[1]-desloc):\n",
    "            # Sobreposição do kernel sobre a imagem\n",
    "            if canais == 1:\n",
    "                prod = arr_orig[y-desloc:y+desloc+1,x-desloc:x+desloc+1]*k[i-desloc:i+desloc+1,j-desloc:j+desloc+1]\n",
    "                arr[y,x] = np.sum(prod)\n",
    "            else:\n",
    "                for c in range(canais):\n",
    "                    prod = arr_orig[y-desloc:y+desloc+1,x-desloc:x+desloc+1,c]*k[i-desloc:i+desloc+1,j-desloc:j+desloc+1]\n",
    "                    arr[y,x,c] = np.sum(prod)\n",
    "            \n",
    "    # Criação do array resultante\n",
    "    arr = np.round(arr)\n",
    "    if clip:\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    # Extrai somente a parte \"central\" da imagem\n",
    "    arr = arr[desloc:arr.shape[0]-desloc, desloc:arr.shape[1]-desloc]\n",
    "    \n",
    "    if ret_img:\n",
    "        arr = np.uint8(arr)\n",
    "        return Image.fromarray(arr)\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "def convolucao_linear_par(img, k, canais, clip=True, ret_img=True):\n",
    "    tam_k = k.shape[0]\n",
    "    \n",
    "    # Cria array com padding\n",
    "    if canais > 1:\n",
    "        arr = np.zeros((img.height+tam_k, img.width+tam_k, canais))\n",
    "    else:\n",
    "        arr = np.zeros((img.height+tam_k, img.width+tam_k))\n",
    "    # Copia dados da imagem para a \"parte inicial\" do array com padding\n",
    "    if canais > 1:\n",
    "        arr[:arr.shape[0]-tam_k, :arr.shape[1]-tam_k, :] = np.asarray(img)\n",
    "    else:\n",
    "        arr[:arr.shape[0]-tam_k, :arr.shape[1]-tam_k] = np.asarray(img)\n",
    "    arr_orig = arr.copy()\n",
    "    \n",
    "    # Efetua convolução (tamanho par, com referência no pixel superior esquerdo do kernel)\n",
    "    # Percorre apenas posições \"iniciais\"\n",
    "    for y in range(0,arr.shape[0]-tam_k):\n",
    "        for x in range(0,arr.shape[1]-tam_k):\n",
    "            # Sobreposição do kernel sobre a imagem\n",
    "            if canais == 1:\n",
    "                prod = arr_orig[y:y+tam_k,x:x+tam_k]*k[:tam_k,:tam_k]\n",
    "                arr[y,x] = np.sum(prod)\n",
    "            else:\n",
    "                for c in range(canais):\n",
    "                    prod = arr_orig[y:y+tam_k,x:x+tam_k,c]*k[:tam_k,:tam_k]\n",
    "                    arr[y,x,c] = np.sum(prod)\n",
    "    \n",
    "    # Criação do array resultante\n",
    "    arr = np.round(arr)\n",
    "    if clip:\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    # Extrai somente a parte \"central\" da imagem\n",
    "    arr = arr[:arr.shape[0]-tam_k, :arr.shape[1]-tam_k]\n",
    "    \n",
    "    if ret_img:\n",
    "        arr = np.uint8(arr)\n",
    "        return Image.fromarray(arr)\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "def convolucao_linear(img, k, clip=True, ret_img=True):\n",
    "    # Determina o número de canais\n",
    "    if img.mode == 'RGB' or img.mode == 'RGBA':\n",
    "        canais = 3\n",
    "    else:\n",
    "        canais = 1\n",
    "        \n",
    "    if k.shape[0] % 2 == 1:\n",
    "        return convolucao_linear_impar(img,k,canais,clip,ret_img)\n",
    "    else:\n",
    "        return convolucao_linear_par(img,k,canais,clip,ret_img)\n",
    "    \n",
    "def convolucao_impar(img, operacao, tam_k, canais, clip=True, ret_img=True):\n",
    "    # Centro do kernel e deslocamento\n",
    "    desloc = i = j = tam_k // 2\n",
    "    \n",
    "    # Cria array com padding\n",
    "    if canais > 1:\n",
    "        arr = np.zeros((img.height+2*desloc, img.width+2*desloc, canais))\n",
    "    else:\n",
    "        arr = np.zeros((img.height+2*desloc, img.width+2*desloc))\n",
    "    # Copiar dados da imagem para o \"centro\" do array com padding\n",
    "    if canais > 1:\n",
    "        arr[desloc:arr.shape[0]-desloc,desloc:arr.shape[1]-desloc,:] = np.asarray(img)\n",
    "    else:\n",
    "        arr[desloc:arr.shape[0]-desloc,desloc:arr.shape[1]-desloc] = np.asarray(img)\n",
    "    arr_orig = arr.copy()\n",
    "    \n",
    "    # Efetua convolução (tamanho ímpar, com referência no centro do kernel)\n",
    "    # Percorre apenas posições \"internas\"\n",
    "    for y in range(desloc,arr.shape[0]-desloc):\n",
    "        for x in range(desloc,arr.shape[1]-desloc):\n",
    "            # Sobreposição do kernel sobre a imagem\n",
    "            if canais > 1:\n",
    "                arr[y,x,:] = operacao(arr_orig[y-desloc:y+desloc+1,x-desloc:x+desloc+1,:])\n",
    "            else:\n",
    "                arr[y,x] = operacao(arr_orig[y-desloc:y+desloc+1,x-desloc:x+desloc+1])\n",
    "    \n",
    "    # Criação do array resultante\n",
    "    arr = np.round(arr)\n",
    "    if clip:\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    # Extrai somente a parte \"central\" da imagem\n",
    "    arr = arr[desloc:arr.shape[0]-desloc, desloc:arr.shape[1]-desloc]\n",
    "    \n",
    "    if ret_img:\n",
    "        arr = np.uint8(arr)\n",
    "        return Image.fromarray(arr)\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "def convolucao_par(img, operacao, tam_k, canais, clip=True, ret_img=True):\n",
    "    # Cria array com padding\n",
    "    if canais > 1:\n",
    "        arr = np.zeros((img.height+tam_k, img.width+tam_k, canais))\n",
    "    else:\n",
    "        arr = np.zeros((img.height+tam_k, img.width+tam_k))\n",
    "    # Copia dados da imagem para a \"parte inicial\" do array com padding\n",
    "    if canais > 1:\n",
    "        arr[:arr.shape[0]-tam_k, :arr.shape[1]-tam_k, :] = np.asarray(img)\n",
    "    else:\n",
    "        arr[:arr.shape[0]-tam_k, :arr.shape[1]-tam_k] = np.asarray(img)\n",
    "    arr_orig = arr.copy()\n",
    "    \n",
    "    # Efetua convolução (tamanho par, com referência no pixel superior esquerdo do kernel)\n",
    "    # Percorre apenas posições \"iniciais\"\n",
    "    for y in range(0,arr.shape[0]-tam_k):\n",
    "        for x in range(0,arr.shape[1]-tam_k):\n",
    "            # Sobreposição do kernel sobre a imagem\n",
    "            if canais > 1:\n",
    "                arr[y,x,:] = operacao(arr_orig[y:y+tam_k,x:x+tam_k,:])\n",
    "            else:\n",
    "                arr[y,x] = operacao(arr_orig[y:y+tam_k,x:x+tam_k])\n",
    "    \n",
    "    # Criação do array resultante\n",
    "    arr = np.round(arr)\n",
    "    if clip:\n",
    "        arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    # Extrai somente a parte \"central\" da imagem\n",
    "    arr = arr[:arr.shape[0]-tam_k, :arr.shape[1]-tam_k]\n",
    "    \n",
    "    if ret_img:\n",
    "        arr = np.uint8(arr)\n",
    "        return Image.fromarray(arr)\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "# Convolução \"genérica\": recebe função como parâmetro\n",
    "def convolucao(img, operacao, tam_k, clip=True, ret_img=True):\n",
    "    # Determina o número de canais\n",
    "    if img.mode == 'RGB' or img.mode == 'RGBA':\n",
    "        canais = 3\n",
    "    else:\n",
    "        canais = 1\n",
    "        \n",
    "    if tam_k % 2 == 1:\n",
    "        return convolucao_impar(img, operacao, tam_k, canais, clip, ret_img)\n",
    "    else:\n",
    "        return convolucao_par(img, operacao, tam_k, canais, clip, ret_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('imagens/vermelho.png')\n",
    "img=getArrayCinza(img)\n",
    "img=Image.fromarray(equaliza(img))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45061461",
   "metadata": {},
   "source": [
    "### 2.3 Realce em imagem embassada\n",
    "\n",
    "<p>A imagem abaixo foi adquirida, intencionalmente, para estar desfocada, a fim de emular um defeito de aquisição.</p>\n",
    "\n",
    "<img src=\"imagens/ufv_desfocado.jpg\" width=\"40%\">\n",
    "\n",
    "<p>O arquivo da foto defeituosa encontra-se em <code>imagens/ufv_desfocado.jpg</code>.</p>\n",
    "\n",
    "<p>Deseja-se amenizar o problema da identificação de forma, usando algum tipo de processamento sobre a mesma.</p>\n",
    "\n",
    "<p><font color=\"red\">Adicione, a seguir, quantas células desejar e implemente</font> código(s) que visa(m) destacar as formas dos objetos borrados por meio do filtro generalizado de nitidez, visto em aula. Leve em conta:</p>\n",
    "\n",
    "- Pode-se aproveitar soluções já feitas por você ou que tenha usado no trabalho anterior, se desejar\n",
    "- O resultado final <b>deve</b> estar em formato colorido RGB\n",
    "- Teste diferentes valores para o parâmetro $k$, do filtro\n",
    "- A imagem original já se encontra desfocada, então certos filtros de suavização (usados como uma etapa do highboost) podem não produzir um bom resultado. Teste diferentes filtros, incluindo os não lineares.\n",
    "- Produza um resultado para <i>Highboost</i> e um para realce atenuado, conforme descrito em aula e no material\n",
    "\n",
    "<p><b>Exemplo de resultado:</b></p>\n",
    "\n",
    "<p>A primeira versão é um caso de <i>Highboost</i>. A segunda versão é uma implementação usando um filtro de realce atenuado e um método de suavização diferente do primeiro. Note que a mudança do filtro de suavização também influencia no resultado</p>\n",
    "\n",
    "<img src=\"imagens/exemplos/highboost.png?2\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ffe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mediana(M):\n",
    "    if len(M.shape) == 3:\n",
    "        ret = []\n",
    "        for c in range(M.shape[2]):\n",
    "            ret.append(np.median(M[:,:,c]))\n",
    "        return np.array(ret)\n",
    "    else:\n",
    "        return np.median(M)\n",
    "    \n",
    "def _maximo(M):\n",
    "    if len(M.shape) == 3:\n",
    "        ret = []\n",
    "        for c in range(M.shape[2]):\n",
    "            ret.append(np.max(M[:,:,c]))\n",
    "        return np.array(ret)\n",
    "    else:\n",
    "        return np.max(M)\n",
    "def suavizacao_mediana(img, tam_k):\n",
    "    return convolucao(img, _mediana, tam_k)\n",
    "\n",
    "def suavizacao_maximo(img, tam_k):\n",
    "    return convolucao(img, _maximo, tam_k)\n",
    "def suavizacao_gauss(img, tam_k, sigma=1):\n",
    "    # Lança exceção, se tamanho do filtro for par\n",
    "    if tam_k % 2 == 0:\n",
    "        raise Exception('\\n\\n\\nErro!! O tamanho do kernel deve ser ímpar!!\\n\\n\\n')\n",
    "    \n",
    "    # Cria kernel\n",
    "    x = np.arange(-(tam_k-1)/2, (tam_k-1)/2+1)\n",
    "    y = np.arange(-(tam_k-1)/2, (tam_k-1)/2+1)\n",
    "\n",
    "    h1,h2 = np.meshgrid(x,y)\n",
    "\n",
    "    hg = np.exp(-(h1**2 + h2**2) / (2*sigma**2))\n",
    "    h = hg / np.sum(hg)\n",
    "\n",
    "    # Retorna convolução\n",
    "    return convolucao_linear(img,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgOrig=Image.open('imagens/ufv_desfocado.jpg')\n",
    "arrOrig = np.asarray(imgOrig, dtype=float)\n",
    "suavehigh=suavizacao_mediana(imgOrig,3)\n",
    "arrSuavehigh = np.asarray(suavehigh, dtype=float)\n",
    "high = np.uint8(np.clip(arrOrig + 4*(arrOrig - arrSuavehigh), 0, 255))\n",
    "imghigh = Image.fromarray(high)\n",
    "suaveatenuado=suavizacao_maximo(imgOrig,9)\n",
    "arrSuaveatenuado = np.asarray(suaveatenuado, dtype=float)\n",
    "atenuado = np.uint8(np.clip(arrOrig + 0.5*(arrOrig - arrSuaveatenuado), 0, 255))\n",
    "imgatenuado = Image.fromarray(atenuado)\n",
    "exibe_bloco([imgOrig,imghigh,imgatenuado], ['Original','imghigh','atenuado'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fabac6",
   "metadata": {},
   "source": [
    "## 3. Filtro de Gradiente\n",
    "\n",
    "<p><font color=\"red\">Adicione, a seguir, quantas células desejar de desenvolva</font> código(s) que implemente(m) uma versão do <b>filtro de Canny</b>, visto em aula. Leve em conta:</p>\n",
    "\n",
    "- Pode-se aproveitar soluções já feitas por você ou que tenha usado no trabalho anterior, se desejar\n",
    "- O resultado final <b>deve</b> estar em formato colorido \"pseudo-binário\", conforme já descrito\n",
    "- As imagens de entrada nos exemplos estão na pasta <code>imagens</code> e são: <code>ipe.jpg</code>, <code>mtstmichel.jpg</code> e <code>ufv.png</code>.\n",
    "\n",
    "<p><b>Exemplos de resultado:</b></p>\n",
    "\n",
    "<img src=\"imagens/exemplos/ipe.jpg\" width=\"80%\">\n",
    "<img src=\"imagens/exemplos/mtstmichel.jpg\" width=\"80%\">\n",
    "<img src=\"imagens/exemplos/ufv.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e88051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_combinado(img, kernels):\n",
    "    k1 = np.array(kernels[0])\n",
    "    k2 = np.array(kernels[1])\n",
    "    primeiro=convolucao_linear(img, k1, clip=False, ret_img=False)\n",
    "    segundo=convolucao_linear(img, k2, clip=False, ret_img=False)\n",
    "    return primeiro,segundo\n",
    "def sobel(img):\n",
    "    k1 = [[-1, -2, -1],\n",
    "          [0, 0, 0],\n",
    "          [1, 2, 1]]\n",
    "    k2 = [[-1, 0, 1],\n",
    "          [-2, 0, 2],\n",
    "          [-1, 0, 1]]\n",
    "    \n",
    "    return filtro_combinado(img, [k1,k2])\n",
    "def supressao(G,angulo):\n",
    "    angulo=angulo*(180/3.14)\n",
    "    angulo[angulo<0]+=180\n",
    "    z=np.zeros_like(G,dtype=float)\n",
    "    for i in range(1,G.shape[0]-1):\n",
    "        for j in range(1,G.shape[1]-1):\n",
    "            q=255\n",
    "            r=255\n",
    "            if 0<=angulo[i][j]<22.5 or 157.5<=angulo[i][j]<=180:\n",
    "                q=G[i,j+1]\n",
    "                r=G[i,j-1]\n",
    "            elif 22.5<=angulo[i][j]<67.5:\n",
    "                q=G[i+1,j-1]\n",
    "                r=G[i-1,j+1]\n",
    "            elif 67.5<=angulo[i][j]<112.5:\n",
    "                q=G[i+1,j]\n",
    "                r=G[i-1,j]\n",
    "            elif 112.5<=angulo[i][j]<157.5:\n",
    "                q=G[i-1,j-1]\n",
    "                r=G[i+1,j+1]\n",
    "            if G[i,j]>=q and G[i,j]>=r:\n",
    "                z[i,j]=G[i,j]\n",
    "    return z\n",
    "def duplo(z,al,be):\n",
    "    r=np.zeros_like(z,dtype=float)\n",
    "    b=be*np.amax(z)\n",
    "    a=al*b\n",
    "    f=np.round(b)+1\n",
    "    F=255\n",
    "    r[z>=b]=F\n",
    "    for i in range(z.shape[0]):\n",
    "        for j in range(z.shape[1]):\n",
    "            if a<=z[i,j]<b:\n",
    "                r[i,j]=f\n",
    "    return r,f,F\n",
    "def final(r,f,F):\n",
    "    for i in range(1,r.shape[0]-1):\n",
    "        for j in range(1,r.shape[1]-1):\n",
    "            if r[i,j]==f:\n",
    "                for k in range(-1,2):\n",
    "                    for c in range(-1,2):\n",
    "                        if r[k,c]==F:\n",
    "                            r[i,j]=F\n",
    "                            break;\n",
    "                if r[i,j]==f:\n",
    "                    r[i,j]=0\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d38e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open('imagens/ipe.jpg')\n",
    "img=getArrayCinza(img)\n",
    "img=Image.fromarray(img)\n",
    "retorno1,retorno2=sobel(img)\n",
    "G = np.clip(np.sqrt((retorno1**2)+(retorno2**2)), 0, 255)\n",
    "angulo=np.zeros_like(retorno1,dtype=float)\n",
    "np.arctan2(retorno1,retorno2,angulo)\n",
    "z=supressao(G,angulo)\n",
    "r,f,F=duplo(z,0.1,0.6)\n",
    "ipe=final(r,f,F)\n",
    "ipe=Image.fromarray(ipe)\n",
    "img=Image.open('imagens/mtstmichel.jpg')\n",
    "img=getArrayCinza(img)\n",
    "img=Image.fromarray(img)\n",
    "retorno1,retorno2=sobel(img)\n",
    "G = np.clip(np.sqrt((retorno1**2)+(retorno2**2)), 0, 255)\n",
    "angulo=np.zeros_like(retorno1,dtype=float)\n",
    "np.arctan2(retorno1,retorno2,angulo)\n",
    "z=supressao(G,angulo)\n",
    "r,f,F=duplo(z,0.1,0.6)\n",
    "mt=final(r,f,F)\n",
    "mt=Image.fromarray(mt)\n",
    "img=Image.open('imagens/ufv.png')\n",
    "img=getArrayCinza(img)\n",
    "img=Image.fromarray(img)\n",
    "retorno1,retorno2=sobel(img)\n",
    "G = np.clip(np.sqrt((retorno1**2)+(retorno2**2)), 0, 255)\n",
    "angulo=np.zeros_like(retorno1,dtype=float)\n",
    "np.arctan2(retorno1,retorno2,angulo)\n",
    "z=supressao(G,angulo)\n",
    "r,f,F=duplo(z,0.1,0.6)\n",
    "ufv=final(r,f,F)\n",
    "ufv=Image.fromarray(ufv)\n",
    "ipe.show()\n",
    "mt.show()\n",
    "ufv.show()\n",
    "exibe_bloco([ipe,mt,ufv], ['ipe','mt','ufv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c585e",
   "metadata": {},
   "source": [
    "## 4. Filtro \"Artístico\"\n",
    "\n",
    "<p><font color=\"red\">Adicione, a seguir, quantas células desejar de desenvolva</font> código(s) que implemente(m) um filtro artístico com aspecto de \"desenho\", como os dos exemplos a seguir. Algumas soluções similares estão nos slides do material de aula.</p>\n",
    "\n",
    "<p>Note que passos comuns envolvem detecção de bordas, saturação de cores, filtros de suavização que uniformizam cores/regiões, obtenção de negativos e filtros espaciais em geral. Esteja livre para usar quaisquer filtros ou técnicas que desejar. Pode-se aproveitar implementações de sala de aula ou do trabalho anterior, para agilizar.</p>\n",
    "\n",
    "<p><b>Importante:</b> <u>para esta atividade apenas</u>, você pode utilizar implementações prontas de filtros de bibliotecas de imagem em Python, como <code>PIL</code>, <code>OpenCV</code>, <code>skimage</code>, <code>ndimage</code> e afins.</p>\n",
    "\n",
    "<p>As imagens utilizadas nos exemplos encontram-se na pasta <code>imagens/</code> e são: <code>ipe.jpg</code>, <code>mtstmichel.jpg</code>, <code>ufv.png</code> e <code>praiaPessoas.png</code>.\n",
    "\n",
    "<p><b>Exemplos de resultado:</b></p>\n",
    "\n",
    "<img src=\"imagens/exemplos/ipe_desenho.jpg\" width=\"100%\">\n",
    "<img src=\"imagens/exemplos/mtstmichel_desenho.jpg\" width=\"100%\">\n",
    "<img src=\"imagens/exemplos/ufv_desenho.png\" width=\"100%\">\n",
    "<img src=\"imagens/exemplos/praiaPessoas_desenho.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgorig=Image.open('imagens/ufv.png')\n",
    "img=getArrayCinza(imgorig)\n",
    "gauss= cv2.GaussianBlur(src=img, ksize=(5,5),sigmaX=0, sigmaY=0)\n",
    "edges = cv2.adaptiveThreshold(gauss, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,3,3)\n",
    "chapada=np.asarray(imgorig)\n",
    "chapada=cv2.medianBlur(chapada,11)\n",
    "chapada=np.asarray(chapada)\n",
    "saida =cv2.bitwise_and(chapada, chapada, mask=-edges)\n",
    "saida=img=Image.fromarray(saida)\n",
    "saida.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf59df",
   "metadata": {},
   "source": [
    "## 5. Transformação geométrica\n",
    "\n",
    "<p><font color=\"red\">Complete o código da função</font> <code>redim</code>, para que a célula de código de teste funcione, apresentando os resultados desejados.</p>\n",
    "\n",
    "<p>A função <code>redim</code> deve receber uma imagem e um fator de proporção como entrada e aplicar este fator para redimensionar a imagem. Por exemplo, se o fator for $0,3$, a imagem resultante terá $30\\%$ do tamanho da original, proporção esta aplicada tanto sobre a altura quanto sobre a largura da imagem original. Se o fator for igual a $1$, a imagem original não é alterada, enquanto que se o fator for superior a $1$, a imagem será ampliada. Por exemplo, para um fator de $1,4$, a imagem resultante será $40\\%$ maior que a original</p>\n",
    "\n",
    "<p>A imagem usada para a célula de teste está na pasta de imagens e é o arquivo <code>capivara.jpg</code>. No entanto, vale você testar com outras das imagens também, para testar se sua implementação funciona para casos gerais.</p>\n",
    "\n",
    "<p><b>Importante:</b> Deste ponto em diante está novamente <b>vetado</b> o uso de funções prontas de bibliotecas Python para imagens.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redim(imagem, fator):\n",
    "    img=np.asarray(imagem)\n",
    "    Y=np.round(fator*img.shape[0])\n",
    "    X=np.round(fator*img.shape[1])\n",
    "    y=np.arange(0,img.shape[0])\n",
    "    x=np.arange(0,img.shape[1])\n",
    "    yredu=np.linspace(0,img.shape[0]-1,int(Y))\n",
    "    xredu=np.linspace(0,img.shape[1]-1,int(X))\n",
    "    saida=np.empty((int(Y),int(X),3),dtype=np.uint8)\n",
    "    interred=interp2d(x,y,img[:,:,0])\n",
    "    intergreen=interp2d(x,y,img[:,:,1])\n",
    "    interblue=interp2d(x,y,img[:,:,2])\n",
    "    saida[:,:,0]=np.round(interred(xredu,yredu)).astype(np.uint8)\n",
    "    saida[:,:,1]=np.round(intergreen(xredu,yredu)).astype(np.uint8)\n",
    "    saida[:,:,2]=np.round(interblue(xredu,yredu)).astype(np.uint8)\n",
    "    return Image.fromarray(saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983834eb",
   "metadata": {},
   "source": [
    "### Célula de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86444764",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('imagens/capivara.jpg')\n",
    "grande = redim(img, 1.5)\n",
    "pequena = redim(img, 0.3)\n",
    "img.show()\n",
    "grande.show()\n",
    "pequena.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88134a",
   "metadata": {},
   "source": [
    "## 6. Detecção de bordas em imagem escura\n",
    "\n",
    "<p>Dada a imagem do arquivo <code>dpi_escuro.png</code>, <font color=\"red\">adicione quantas células desejar a seguir</font> e implemente um código que, mesmo na imagem sob as más condições de luz, seja capaz de identificar potenciais regiões de borda na imagem, conforme ilustrado nas imagens da figura a seguir:</p>\n",
    "\n",
    "<img src=\"imagens/exemplos/corredor.png?2\" width=\"100%\">\n",
    "\n",
    "<p>Uma possível aplicação para este tipo de cenário seria auxiliar um robô, cuja navegação é orientada por meio de uma câmera, a identificar regiões que delimitam objetos para se desviar deles, mesmo com pouca luz.</p>\n",
    "\n",
    "<p>O importante do exercício é identificar as tais potenciais bordas, obtidas a partir da primeira imagem, cujo arquivo é mencionado anteriormente. Ou seja, a <b>terceira</b> (inferior, à esquerda) imagem do exemplo acima é o objetivo. Esta que deverá ser sua resposta ao exercício proposto.</p>\n",
    "\n",
    "<p>A segunda imagem é meramente ilustrativa e é uma outra foto, adquirida separadamente e no mesmo ambiente, porém sujeita a melhores condições de iluminação. Está presente na figura do exemplo apenas para que se verifique a qualidade da detecção das bordas. Ela <u>não</u> é uma versão da imagem original e nem será utilizada, em momento algum, para o desenvolvimento da solução do exercício.</p>\n",
    "\n",
    "<p>Por fim, quarta imagem também é apenas para ilustração. Neste caso, das bordas encontradas superpostas à imagem original, escura. Não é exigida como parte da sua solução. No entanto, se você fizer esta quarta imagem, receberá pontos bônus neste exercício...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('imagens/dpi_escuro.png')\n",
    "cinza=img.convert('L')\n",
    "gauss= suavizacao_gauss(cinza,11)\n",
    "gauss=np.asarray(gauss)\n",
    "equa=equaliza(gauss)\n",
    "equa=Image.fromarray(equa)\n",
    "retorno1,retorno2=sobel(equa)\n",
    "G = np.clip(np.sqrt((retorno1**2)+(retorno2**2)), 0, 255)\n",
    "angulo=np.zeros_like(retorno1,dtype=float)\n",
    "np.arctan2(retorno1,retorno2,angulo)\n",
    "z=supressao(G,angulo)\n",
    "r,f,F=duplo(z,0,0.7)\n",
    "r=final(r,f,F)\n",
    "r=Image.fromarray(np.uint8(np.round(r)))\n",
    "r.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df183cf4",
   "metadata": {},
   "source": [
    "## Considerações finais\n",
    "\n",
    "- Salve seu Notebook e envie, pelo Moodle, apenas ele.\n",
    "- Releia as observações no início do enunciado para checar se não se esqueceu de nenhum item\n",
    "- Confira seus resultados com os exemplos fornecidos, mas também faça testes criados por você\n",
    "\n",
    "<p style=\"text-align: right\">Bons estudos,</p>\n",
    "<p style=\"text-align: right\">Prof. Marcos</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento Digital de Imagens - Trabalho Prático 1\n",
    "\n",
    "## 1. Preparação\n",
    "\n",
    "### a) Edite a célula abaixo, preencha com seus dados pessoais e a execute novamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Aluno(a):</b>\n",
    "\n",
    "<ul>\n",
    "    <li>Matrícula: 98877</li>\n",
    "    <li>Nome: gabriel macedo nunes pontes</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Observações e instruções gerais:\n",
    "\n",
    "- Entregue <b>apenas</b> o notebook resultante do seu trabalho. Não há necessidade de se entregar qualquer outro arquivo.\n",
    "- O trabalho deve ser desenvolvido <b>inidivualmente</b> pelos alunos da Ciência da Computação da UFV. Os alunos de <b>outras instituições e áreas</b> (e apenas estes), podem desenvolver em duplas.\n",
    "- O trabalho é composto por várias tarefas individuais, que não são necessariamente conectadas umas às outras. Cada tarefa tem seu próprio enunciado.\n",
    "- <b>Recomenda-se</b> fazer os exercícios na <b>ordem</b> que estão no Notebook, por algumas razões:\n",
    "    - Embora não estejam necessariamente conectadas umas às outras, em alguns casos estarão.\n",
    "    - A ordem dos exercícios reflete mais ou menos a ordem dos capítulos da disciplina, facilitando os estudos\n",
    "    - As atividades são pensadas para ir construindo conhecimento e praticando implementação aos poucos, portanto, é melhor para o seu aprendizado seguir a ordem\n",
    "- Está <b>vetado</b> o uso de recursos e implementações prontas dos recursos pedidos nas tarefas deste trabalho. Você deve implementar o recurso.\n",
    "    - Exemplo 1: se pedido, como alvo da tarefa, que você implemente/faça a conversão de cinza de uma imagem, você não pode usar a conversão que vem pronta na biblioteca PIl.\n",
    "    - Exemplo 2: se um passo secundário de um algoritmo maior demanda a conversão em cinza de uma imagem, mas não é o foco do exercício, você pode usar a conversão pronta da biblioteca PIL.\n",
    "- Está <b>liberado</b> o uso de outras bibliotecas que desejar incluir, em especial, as não diretamente relacionadas ao conteúdo de PDI.\n",
    "- Caso venha a utilizar alguma solução diferente das vistas em aula e/ou fornecidas no material do professor, coloque a fonte (livro, site etc.) de onde foi tirada sua solução.\n",
    "- Na subpasta <code>imagens/exemplos/</code> encontra-se um Notebook (e as imagens) contendo <b>exemplos</b> resultantes da execução esperada de cada item do trabalho, para que você mesmo(a) possa verificar e checar suas implementações. O Notebook abrirá todas as imagens desta subpasta na ordem correta dos exercícios. No entanto, você pode abri-las separadamente, para analisar em mais detalhes, se desejar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Execute a célula abaixo, que conterá as importações de módulos Python.\n",
    "\n",
    "#### Você é livre para editar e adicionar outras importações a esta célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotagem de gráficos e imagens no notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Manipulação de imagens\n",
    "from PIL import Image\n",
    "from skimage import color # Vamos usar para fazer uma conversão de espaço de cores específica\n",
    "import imghdr # Vamos usar para verificar se um determinado arquivo em disco é uma imagem ou não\n",
    "\n",
    "import numpy as np # Manipulação de arrays\n",
    "import os # Acesso ao sistema de arquivos do SO\n",
    "import random # Geração de números aleatóriso. Você pode precisar em uma das atividades pedidas...\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Funções auxiliares prontas. Execute as células a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Função <code>abre_imagem</code>:</p>\n",
    "<ul>\n",
    "    <li>A partir de um nome de arquivo, retorna dois objetos <code>PIL Image</code>, na versão RGB e em tons de cinza</li>\n",
    "    <li>Em caso de erro ao encontrar arquivo, exibe mensagem de alerta em tela e retorna nulo (<code>None</code>)</li>\n",
    "    <li><u>Parâmetro de entrada:</u> <code>arquivo</code>, <i>string</i> contendo o nome do arquivo de imagem</li>\n",
    "    <li><u>Retorno:</u> objeto <code>PIL Image</code> na versão RGB da imagem</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abre_imagem(arquivo):\n",
    "    if os.path.isfile(arquivo):\n",
    "        img = Image.open(arquivo)\n",
    "        if img.mode == 'L':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        return img\n",
    "    else:\n",
    "        print('\\n\\n\\nErro!!! Arquivo inexistente.\\n\\n\\n')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Função <code>exibe_bloco</code>:</p>\n",
    "<ul>\n",
    "    <li>Exibe, em tela, diversas imagens, em um grid</li>\n",
    "    <li><u>Parâmetros de entrada:</u></li>\n",
    "    <ul>\n",
    "        <li><code>imgs</code>: lista <i>Python</i> contendo $n > 1$ objetos <code>PIL Image</code>, a serem exibidos em tela</li>\n",
    "        <li><code>titulos</code>: lista <i>Python</i> contendo $n$ strings, com o título de cada imagem. Opcional. Se não fornecida, gera títulos automaticamente, com 'Imagem 1', 'Imagem 2' etc.</li>\n",
    "        <li><code>tam_linha</code>: valor inteiro, informando quantas imagens por linha serão exibidas. Opcional. Valor <i>default</i>: 4</li>\n",
    "        <li><code>arquivo</code>: string que, se fornecida, habilita o salvamento da visualização das imagens em um arquivo em memória secundária, usando o nome de arquivo fornecido no parâmetro. Opcional. <i>Default:</i> <code>None</code></li>\n",
    "        <li><code>dpi</code>: <i>float</i> que, se fornecido, determina a resolução da imagem gerada. Opcional. <i>Default</i>: $100$</li>\n",
    "    </ul>\n",
    "    <li>Gera erro se os comprimentos de <code>imgs</code> e <code>titulos</code> não forem os mesmos ou se <code>len(imgs) < 2</code>.</li>\n",
    "    <li><u>Retorno:</u> nenhum</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibe_bloco(imgs, titulos=None, tam_linha=4, arquivo=None, dpi=100):\n",
    "    assert len(imgs) > 1\n",
    "    \n",
    "    # Espaçamento entre imagens (em pixels)\n",
    "    espacamento_x = 15\n",
    "    espacamento_y = 20\n",
    "    \n",
    "    # Calcula o número de linhas\n",
    "    if len(imgs) < tam_linha:\n",
    "        tam_linha = len(imgs)\n",
    "    nlinhas = len(imgs) // tam_linha + int(len(imgs) % tam_linha > 0)\n",
    "    \n",
    "    # Cria lista de arrays e calcula tamanho da imagem de visualização a ser exibida/salva\n",
    "    largura_px = 0\n",
    "    altura_px = 0\n",
    "    i = 0\n",
    "    imagens = []\n",
    "    for img in imgs:\n",
    "        if img.mode == 'L':\n",
    "            img = img.convert('RGB')\n",
    "        imagens.append(np.asarray(img))\n",
    "        if i % tam_linha == 0:\n",
    "            max_altura_linha = 0\n",
    "            largura_linha = 0\n",
    "        largura_linha += img.width\n",
    "        if img.height > max_altura_linha:\n",
    "            max_altura_linha = img.height\n",
    "        if i % tam_linha == tam_linha-1 or i == len(imgs)-1:\n",
    "            altura_px += max_altura_linha\n",
    "            if largura_linha > largura_px:\n",
    "                largura_px = largura_linha\n",
    "        i += 1        \n",
    "    largura_px += (tam_linha-1)*espacamento_x\n",
    "    altura_px += (nlinhas-1)*espacamento_y\n",
    "    largura_inch = largura_px / float(dpi)\n",
    "    altura_inch = altura_px / float(dpi)\n",
    "    \n",
    "    # Cria lista de títulos\n",
    "    if titulos is None:\n",
    "        titulos = []\n",
    "        for i in range(len(imagens)):\n",
    "            titulos.append('Imagem %d' % (i+1))\n",
    "    else:\n",
    "        assert len(imgs) == len(titulos)\n",
    "    \n",
    "    # Plota imagens em grid\n",
    "    plt.rcParams['figure.figsize'] = [largura_inch,altura_inch]\n",
    "    fig, axes = plt.subplots(nrows=nlinhas, ncols=tam_linha)\n",
    "    for i,ax in enumerate(axes.ravel()):\n",
    "        ax.axis('off')\n",
    "        if i < len(imgs):\n",
    "            ax.imshow(imagens[i])\n",
    "            ax.set_title(titulos[i])\n",
    "        else:\n",
    "            fig.delaxes(ax)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Salva, se desejado\n",
    "    if arquivo is not None:\n",
    "        plt.savefig(arquivo, dpi=dpi)\n",
    "        print('Visualização salva em %s.' % arquivo)\n",
    "        \n",
    "    # Exibe\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parte I: ruído, restauração e comparação de imagens\n",
    "\n",
    "### 2.1 Aplicação de ruídos\n",
    "\n",
    "<p>Implemente uma funcionalidade que produza ruı́dos sobre uma imagem. O ruı́do deve ser do tipo “Sal e Pimenta”. O usuário deve fornecer dois parâmetros: o percentual de pixels da imagem afetado pelo ruı́do e a proporção entre sal e pimenta. Isto é, quantos pixels da imagem serão substituı́dos por um pixel de ruı́do (sal: branco, pimenta: preto) e, dentro deste conjunto de pixels, quantos porcento serão de sal e quantos serão de pimenta. O ruı́do deve ser distribuı́do em pixels aleatórios da imagem.</p>\n",
    "\n",
    "<p><font color=\"red\">Complete a função abaixo</font> para que o código da célula de teste funcione corretamente:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salpimenta(imgOrig, percent=0.15, propSalPim=0.5):\n",
    "    array=np.asarray(imgOrig)\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            chance=random.random()\n",
    "            if chance<=percent:\n",
    "                prop=random.random()\n",
    "                if prop<propSalPim:\n",
    "                    array[i,j,:]=255\n",
    "                else:\n",
    "                    array[i,j,:]=0\n",
    "    \n",
    "    img=Image.fromarray(np.uint8(array))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste seu código executando a célula a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/lavoura.jpg')\n",
    "imgRuido = salpimenta(img, percent=0.02, propSalPim=0.4)\n",
    "exibe_bloco([img, imgRuido], ['Imagem Original', 'Imagem com Ruído'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Restauração de imagens com ruídos\n",
    "\n",
    "<p>Este exercício visa emular o seguinte cenário: uma câmera de vigilância hipotética monitora um ambiente, um corredor. No entanto, esta câmera está com defeito, sofrendo interferência no seu sinal devido a uma fonte de radiação eletromagnética próxima. Isto faz com que em cada frame capturado, a imagem do corredor apresenta um certo grau de ruído em comportamento aparentemente aleatório.</p>\n",
    "\n",
    "<p>Na subpasta <code>imagens/ruidosas/</code> encontram-se 100 exemplos de frames \"capturados\" nesta câmera hipotética. Abra a pasta e analise seu conteúdo. Observe bem os nomes dos arquivos (isto pode ajudar na sua implementação) e veja como o ruído se comporta em cada frame (apenas de curiosidade).</p>\n",
    "\n",
    "<p>A tarefa consiste em tentar gerar uma imagem de boa qualidade a partir dos frames ruidosos. Uma técnica bastante simples consiste em pegar uma amostra dos frames e gerar uma imagem cujos pixels são a média (arredondada para o inteiro mais próximo) dos valores dos pixels equivalentes (i.e.: mesmas coordenadas) nas imagens ruins.</p>\n",
    "\n",
    "<p><font color=\"red\">Implemente uma função</font> na célula a seguir para que o código de teste da célula funcione corretamente. Para fins de padronização apenas, chame esta função de <code>reconstroi</code> e ela deve receber como parâmetro obrigatório, <b>pelo menos</b> um inteiro <i>n</i>, representando o número de amostras utilizadas para calcular a média. Se $n=3$, significa que as 3 primeiras imagens da pasta serão utilizadas apenas, se $n=45$, as 45 primeiras serão utilizadas, e assim por diante até o valor máximo de 100 amostras.</p>\n",
    "\n",
    "<p>Observações</p>\n",
    "<ol>\n",
    "    <li>Você pode acrescentar mais parâmetros, obrigatórios ou não, além de $n$, na função <code>reconstroi</code></li>\n",
    "    <li>O retorno da função deve ser um objeto <code>PIL Image</code>, contendo a imagem reconstruída pela média</li>\n",
    "    <li>Adapte o código da célula de teste da implementação para que a evocação da função que você implementou fique compatível com o trecho de código de teste.</li>\n",
    "    <li>Os frames da suposta câmera defeituosas foram gerados adicionando-se ruídos sobre uma mesma imagem original, que se encontra em <code>imgens/corredor_claro.jpg</code>, para te auxiliar na depuração da tarefa, você pode abri-la para comparar a imagem retornada pela função com a foto original.</li>\n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstroi(n, nome_base_arquivo):\n",
    "    img = Image.open(nome_base_arquivo % 1)\n",
    "    imgMed=np.zeros_like(img,dtype=float)\n",
    "    for i in range(1,n+1):\n",
    "        img1 = Image.open(nome_base_arquivo % i)\n",
    "        temp=np.asarray(img1,dtype=float)\n",
    "        imgMed=temp+imgMed\n",
    "    imgMed=imgMed/n\n",
    "    imgMed=Image.fromarray(np.uint8(imgMed))\n",
    "    # Você pode alterar o nome da variável de retorno à vontade\n",
    "    return imgMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste seu código executando a célula a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/corredor_claro.jpg')\n",
    "# Número de amostras\n",
    "n = 20\n",
    "imgMedia = reconstroi(n, 'imagens/ruidosas/ruidosa%03d.png')\n",
    "exibe_bloco([img, imgMedia], ['Imagem original', 'Imagem reconstruída com com %d amostras' % n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Comparação de imagens - parte 1\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>nmse</code>, que deve receber duas imagens <code>PIL Image</code> como entrada e retornar a métrica de similaridade NMSE (<i>Normalized Mean Square Error</i>), como resposta (ver aula assíncrona sobre o assunto).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(img1, img2):\n",
    "    f = np.asarray(img1, dtype=float)\n",
    "    g = np.asarray(img2, dtype=float)\n",
    "    v=(np.sum((f-g)**2)/np.sum(f**2))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Comparação de imagens - parte 2\n",
    "\n",
    "<p>Retomando o exercício do item 2.2, vamos analisar agora como a variação do tamanho da amostra de imagens ruidosas afeta a qualidade da imagem reconstruída. Para isto, o código abaixo testa tamanhos de amostra de 1 a 100 imagens e compara o resultado obtido com a imagem original (limpa, sem ruídos), utilizando a métrica NMSE.</p>\n",
    "\n",
    "<p><font color=\"red\">Adapte</font> o código abaixo para que as chamadas às funções <code>reconstroi</code>e <code>nmse</code> fiquem compatíveis com as que você implementou, e então execute a célula. Um gráfico deve ser exibido em tela, além de algumas mensagens de progresso do andamento dos cálculos.</p>\n",
    "\n",
    "<p><b>Obs.:</b> a geração do gráfico pode levar algum tempo de execução</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre imagem original e descarta a versão em tons de cinza\n",
    "img = abre_imagem('imagens/corredor_claro.jpg')\n",
    "\n",
    "# O gráfico precisará de valores para os eixos x e y. Serão salvos em listas\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# Testa os vários tamanhos de amostra\n",
    "for tam in range(1,101):\n",
    "    # Exibe status do progresso a cada 10 imagens, até a última\n",
    "    if tam % 10 == 0 or tam == 1:\n",
    "        print('Processando para %d imagens...' % tam)\n",
    "        \n",
    "    # Cria a imagem reconstruída\n",
    "    ####### ADAPTE AQUI, SE NECESSÁRIO #######\n",
    "    imgMed = reconstroi(tam, 'imagens/ruidosas/ruidosa%03d.png')\n",
    "    \n",
    "    # Computa a diferença/semelhança entre a imagem reconstruída e original\n",
    "    ####### ADAPTE AQUI, SE NECESSÁRIO #######\n",
    "    dif = nmse(img, imgMed)\n",
    "    # Acrescenta o tamanho da amostra na lista de valores do eixo x\n",
    "    x.append(tam)\n",
    "    # Acrescenta a diferença das imagens na lista de valores do eixo y\n",
    "    y.append(dif)\n",
    "\n",
    "# Plota resultado\n",
    "plt.rcParams['figure.figsize'] = [5,5]\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Tamanho da amostra')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Diferença entre imagem reconstruída e original')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisando o gráfico produzido, responda as duas questões a seguir\n",
    "\n",
    "<p><b>2.4.1</b> O que você pode concluir, analisando o gráfico, a respeito da relação entre o número de frames utilizados e a qualidade da imagem produzida, em relação à imagem original? (escreva sua resposta na célula a seguir)</p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quanto maior o numero de frames mais parecida com a original vai ser,porém quanto maior o numero de frames menor a diferença ao acrecentar mais frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>2.4.2</b> Imagine agora que se deseja implementar um algoritmo que analise o vídeo da câmera e gere um novo vídeo com uma taxa de frames menor, porém com melhor qualidade. Isto poderia ser feito utilizando a técnica vista aqui, calculando a imagem média a cada intervalo de $n$ frames, que produziriam um único frame do vídeo de maior qualidade. Este vídeo pós-processado teria uma taxa de frames por segundo $\\frac{1}{n}$ menor que o original. Este seria o preço pago ao se aumentar a qualidade visual.</p>\n",
    "\n",
    "<p>Portanto, a fim de otimizar o resultado, seria interessante utilizar o menor tamanho $n$ que gerasse um resultado de qualidade visual satisfatória, visando fazer com que a taxa de frames por segundo caísse o mínimo possível em relação ao vídeo original. Analisando o gráfico, em torno de qual valor você sugeriria para $n$? Por que? (escreva sua resposta na célula a seguir).</p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7,pois pelo gráfico produzido a curva se acentua perto de onde o nmse vale 0.01 e o valor de n igual a 7 é a primeira vez que o rmse fica menor que 0.01,aumentar diminuiria a taxa de frames e a qualidade da imagem não aumentaria de forma proporcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parte II: manipulando cores\n",
    "\n",
    "### 3.1 Mudando saturação de cores em uma imagem\n",
    "\n",
    "<p>A saturação é um parâmetro das cores que indica o grau de mesclagem do matiz da cor com a cor branca. Alguns modelos de cor, alternativos ao RGB, utilizam este parâmetro como um dos componentes para formar as cores que vemos, como os modelos conhecidos como HSV (<i>Hue</i>/Matiz, <i>Saturation</i>/Saturação, <i>Value</i>/Valor) e HSL (<i>Hue</i>/Matiz, <i>Saturation</i>/Saturação, <i>Lightness</i>/Luminosidade).</p>\n",
    "\n",
    "<p>Podemos, portanto, converter a representação de uma imagem RGB para um desses modelos, alterar o parâmetro de saturação das cores usando este sistema e converter o resultado de volta para RGB. Neste exercício, faremos isso usando o sistema HSL. O algoritmo geral para o processo é algo como o descrito a seguir...</p>\n",
    "\n",
    "1. Converta a imagem de RGB para HSL: $Im' = rgb2hsl(Im)$\n",
    "2. Multiplique o canal de saturação ($S$) de $Im'$ por um fator $f \\in [-1,1]$\n",
    "3. Converta a imagem resultante de volta para RGB: $Im'' = hsl2rgb(Im')$\n",
    "\n",
    "<p>Embora você possa encontrar funções para conversão $RGB \\rightarrow HSL$ e vice-versa em alguns pacotes Python para manipulação de imagens, você deve implementar todos passos do algoritmo acima. Portanto, <font color=\"red\">crie funções</font> para:</p>\n",
    "\n",
    "- Converter valores RGB para HSL, chamada <code>rgb2hsl</code>\n",
    "- Converter valores HSL para RGB, chamada <code>hsl2rgb</code>\n",
    "- Alterar a saturação de uma imagem, usando as funções acima, a função deve-se chamar <code>satura</code>\n",
    "\n",
    "<p>Crie pelo menos as três funções pedidas. Você pode criar mais funções ou funções auxiliares, se assim desejar. Uma outra dica para o desenvolvimento é comparar seus resultados de conversão de modelos de cor com os resultados obtidos usando as funções já prontas em pacotes e bibliotecas.</p>\n",
    "\n",
    "#### Conversão RGB para HSL:\n",
    "\n",
    "- $R' \\leftarrow \\frac{R}{255}$\n",
    "- $G' \\leftarrow \\frac{G}{255}$\n",
    "- $B' \\leftarrow \\frac{B}{255}$\n",
    "- $C_{max} \\leftarrow max(R', G',B')$\n",
    "- $C_{min} \\leftarrow min(R', G',B')$\n",
    "- $\\Delta \\leftarrow C_{max} - C_{min}$\n",
    "- $L \\leftarrow \\frac{C_{max} - C_{min}}{2}$\n",
    "- Cálculo de $H$:\n",
    "    - $H \\leftarrow 0$, se $\\Delta = 0$\n",
    "    - $H \\leftarrow 60 \\cdot \\left(\\frac{G'-B'}{\\Delta} mod 6 \\right)$, se $C_{max} = R'$\n",
    "    - $H \\leftarrow 60 \\cdot \\left(\\frac{B'-R'}{\\Delta} + 2 \\right)$, se $C_{max} = G'$\n",
    "    - $H \\leftarrow 60 \\cdot \\left(\\frac{R'-G'}{\\Delta} + 4 \\right)$, se $C_{max} = B'$\n",
    "- Cálculo de $S$:\n",
    "    - $S \\leftarrow 0$, se $\\Delta = 0$\n",
    "    - $S \\leftarrow \\frac{\\Delta}{1 - |2L-1|}$, se $\\Delta \\neq 0$\n",
    "    \n",
    "#### Conversão HSL para RGB:\n",
    "\n",
    "- $C = (1 - |2L - 1|) \\cdot S$\n",
    "- $X = C \\cdot (1 - |\\left(\\frac{H}{60} mod 2\\right) - 1|)$\n",
    "- $m = L - \\frac{C}{2}$\n",
    "- Cálculo de $R'$, $G'$ e $B'$:\n",
    "    - $(R',G',B') \\leftarrow (C,X,0)$, se $0 \\leq H < 60$\n",
    "    - $(R',G',B') \\leftarrow (X,C,0)$, se $60 \\leq H < 120$\n",
    "    - $(R',G',B') \\leftarrow (0,C,X)$, se $120 \\leq H < 180$\n",
    "    - $(R',G',B') \\leftarrow (0,X,C)$, se $180 \\leq H < 240$\n",
    "    - $(R',G',B') \\leftarrow (X,0,C)$, se $240 \\leq H < 300$\n",
    "    - $(R',G',B') \\leftarrow (C,0,X)$, se $300 \\leq H < 360$\n",
    "- $R \\leftarrow arredonda((R' + m) \\cdot 255)$\n",
    "- $G \\leftarrow arredonda((B' + m) \\cdot 255)$\n",
    "- $B \\leftarrow arredonda((B' + m) \\cdot 255)$\n",
    "\n",
    "#### Saturação:\n",
    "- Informe:\n",
    "    - Imagem $Im$\n",
    "    - $\\textrm{fator} \\in [0,2]$\n",
    "- $f \\leftarrow \\textrm{fator} - 1$\n",
    "- Converta $Im$ para HSL, produzindo $Im'$\n",
    "- Ajuste da saturação:\n",
    "    - $S \\leftarrow \\textrm{canal } S, \\textrm{ de } Im'$\n",
    "    - $S \\leftarrow S + \\textrm{f} \\cdot (1 - S) \\cdot S$, se $\\textrm{f} \\geq 0$\n",
    "    - $S \\leftarrow S + \\textrm{f} \\cdot S$, se $\\textrm{f} < 0$\n",
    "- Converta $Im'$ para RGB, produzindo $Im''$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsl2rgb(arr):\n",
    "    imgrgb=np.empty_like(arr)\n",
    "    for x in range(arr.shape[0]):\n",
    "        for y in range(arr.shape[1]):\n",
    "            c=((1-abs(2*arr[x][y][2]-1))*arr[x][y][1])\n",
    "            X=c*(1-abs(((arr[x][y][0]/60)%2)-1))\n",
    "            m=arr[x][y][2]-(c/2)\n",
    "            if 0<=arr[x][y][0]<60:\n",
    "                imgrgb[x][y][0]=c\n",
    "                imgrgb[x][y][1]=X\n",
    "                imgrgb[x][y][2]=0\n",
    "            elif 60<=arr[x][y][0]<120:\n",
    "                imgrgb[x][y][0]=X\n",
    "                imgrgb[x][y][1]=c\n",
    "                imgrgb[x][y][2]=0\n",
    "            elif 120<=arr[x][y][0]<180:\n",
    "                imgrgb[x][y][0]=0\n",
    "                imgrgb[x][y][1]=c\n",
    "                imgrgb[x][y][2]=X\n",
    "            elif 180<=arr[x][y][0]<240:\n",
    "                imgrgb[x][y][0]=0\n",
    "                imgrgb[x][y][1]=X\n",
    "                imgrgb[x][y][2]=c\n",
    "            elif 240<=arr[x][y][0]<300:\n",
    "                imgrgb[x][y][0]=X\n",
    "                imgrgb[x][y][1]=0\n",
    "                imgrgb[x][y][2]=c\n",
    "            elif 300<=arr[x][y][0]<360:\n",
    "                imgrgb[x][y][0]=c\n",
    "                imgrgb[x][y][1]=0\n",
    "                imgrgb[x][y][2]=X\n",
    "            imgrgb[x][y][0]=round((imgrgb[x][y][0]+m)*255)\n",
    "            imgrgb[x][y][1]=round((imgrgb[x][y][1]+m)*255)\n",
    "            imgrgb[x][y][2]=round((imgrgb[x][y][2]+m)*255)\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return Image.fromarray(np.uint8(imgrgb))\n",
    "\n",
    "def rgb2hsl(arr):\n",
    "    imghsl=np.empty_like(arr,dtype=float)\n",
    "    for x in range(arr.shape[0]):\n",
    "        for y in range(arr.shape[1]):\n",
    "            R=arr[x][y][0]/255\n",
    "            G=arr[x][y][1]/255\n",
    "            B=arr[x][y][2]/255\n",
    "            maximo=max((R,G,B))\n",
    "            minimo=min((R,G,B))\n",
    "            delta=maximo-minimo\n",
    "            imghsl[x][y][2]=(maximo+minimo)/2.0\n",
    "            if delta==0:\n",
    "                imghsl[x][y][0]=0\n",
    "            elif maximo==R:\n",
    "                imghsl[x][y][0]=((((G-B)/delta)%6)*60)\n",
    "            elif maximo==G:\n",
    "                imghsl[x][y][0]=((((B-R)/delta)+2)*60)\n",
    "            elif maximo==B:\n",
    "                imghsl[x][y][0]=((((R-G)/delta)+4)*60)\n",
    "            temp=(1-abs(2*imghsl[x][y][2]-1))\n",
    "            if temp==0:\n",
    "                temp=1\n",
    "            imghsl[x][y][1]=(delta/temp)\n",
    "    return imghsl\n",
    "\n",
    "def satura(img, fator):\n",
    "    arr=np.asarray(img)\n",
    "    hsl=rgb2hsl(arr)\n",
    "    f=fator-1\n",
    "    for x in range(hsl.shape[0]):\n",
    "        for y in range(hsl.shape[1]):\n",
    "            if f>=0:\n",
    "                hsl[x][y][1]=hsl[x][y][1]+f*(1-hsl[x][y][1])* hsl[x][y][1]\n",
    "            else:\n",
    "                hsl[x][y][1]=hsl[x][y][1]+f*hsl[x][y][1]\n",
    "    imgsat=hsl2rgb(hsl)\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return imgsat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo, para testar seu código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/capivara.jpg')\n",
    "imagens = [img]\n",
    "titulos = ['Original']\n",
    "\n",
    "fatores = [0, 0.5, 1, 1.5, 2]\n",
    "\n",
    "for fator in fatores:\n",
    "    saturada = satura(img, fator=fator)\n",
    "    imagens.append(saturada)\n",
    "    titulos.append('Saturação fator=%.1f' % fator)\n",
    "\n",
    "exibe_bloco(imagens, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Alargamento de contraste\n",
    "\n",
    "<p><font color=\"red\">Complete a função abaixo</font>, que deve implementar a técnica de alargamento de contraste, vista nas aulas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alargaContraste(img):\n",
    "    f=np.asarray(img)\n",
    "    n=np.empty(f.shape)\n",
    "    for canal in range(3):\n",
    "        n[:,:,canal]=((f[:,:,canal]-np.min(f[:,:,canal]))/(np.max(f[:,:,canal])-np.min(f[:,:,canal])))*255\n",
    "    imgAlarg=Image.fromarray(np.uint8(np.round(n)))\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return imgAlarg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo, para testar seu código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/praiaRuim.png')\n",
    "imgOrig = abre_imagem('imagens/praiaOrig.png')\n",
    "\n",
    "fatores = [0.5,1.5,2]\n",
    "\n",
    "for fator in fatores:\n",
    "    imgs = []\n",
    "    titulos = []\n",
    "\n",
    "    imgs.append(imgOrig)\n",
    "    titulos.append('Original')\n",
    "\n",
    "    imgs.append(img)\n",
    "    titulos.append('Defeituosa')\n",
    "\n",
    "    imgAlarg = alargaContraste(img)\n",
    "    imgs.append(imgAlarg)\n",
    "    titulos.append('Alarg. de Cont. sobre Defeituosa')\n",
    "\n",
    "    imgAlarg = alargaContraste(imgOrig)\n",
    "    imgs.append(imgAlarg)\n",
    "    titulos.append('Alarg. de Cont. sobre Original')\n",
    "\n",
    "    imgSat = satura(img, fator)\n",
    "    imgs.append(imgSat)\n",
    "    titulos.append('Defeituosa Saturada com fator %.1f' % fator)\n",
    "\n",
    "    imgSat = satura(imgOrig, fator)\n",
    "    imgs.append(imgSat)\n",
    "    titulos.append('Original Saturada com fator %.1f' % fator)\n",
    "\n",
    "    imgAlarg = alargaContraste(img)\n",
    "    imgSat = satura(imgAlarg, fator)\n",
    "    imgs.append(imgSat)\n",
    "    titulos.append('Defeituosa Alarg. e Saturada com fator %.1f' % fator)\n",
    "    \n",
    "    imgSat = satura(img, fator)\n",
    "    imgAlarg = alargaContraste(imgSat)\n",
    "    imgs.append(imgAlarg)\n",
    "    titulos.append('Defeituosa Saturada com fator %.1f e Alarg.' % fator)\n",
    "\n",
    "    exibe_bloco(imgs, titulos, dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Reconstruindo e decompondo imagens\n",
    "\n",
    "<p>Em uma aula prática, foi feito um exercício onde uma imagem RGB foi reconstruída a partir de três imagens auxiliares, cada uma contendo a informação dos canais R, G e B, em separado. Neste exercício, deve-se fazer as reconstituições descritas nos itens a seguir.</p>\n",
    "\n",
    "#### 3.3.1 Reconstrução direta por canais RGB\n",
    "\n",
    "<p>A primeira reconstrução é exatamente a que foi feita na aula prática. Para isto, na subpasta <code>imagens/canais/</code> existem 3 arquivos (entre outros): <code>canalR.png</code>, <code>canalG.png</code> e <code>canalB.png</code>. Deve-se repetir a reconstrução feita em aula prática, recriando a imagem que pode ser vista em <code>imagens/tamburutaca.jpg</code>.</p>\n",
    "\n",
    "<p>Na célula abaixo, faça a implementação, exibindo a imagem resultante.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgR = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalR.png')\n",
    "r = np.asarray(imgR, dtype=int)\n",
    "imgG = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalG.png')\n",
    "g = np.asarray(imgG, dtype=int)\n",
    "imgB = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalB.png')\n",
    "b = np.asarray(imgB, dtype=int)\n",
    "s=np.zeros([r.shape[0],r.shape[1],3])\n",
    "s[:,:,0]=r\n",
    "s[:,:,1]=g\n",
    "s[:,:,2]=b\n",
    "imgS = Image.fromarray(np.uint8(s))\n",
    "imgS.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Reconstrução a partir dos canais HSL\n",
    "\n",
    "<p>A segunda reconstrução também irá recriar a imagem <code>imagens/tamburutaca.jpg</code>, porém, a partir da informação dos canais HSL, salvas em três imagens: <code>imagens/canais/canalH.png</code>, <code>imagens/canais/canalS.png</code> e <code>imagens/canais/canalL.png</code>.</p>\n",
    "\n",
    "<p>Para que o conteúdo seja \"visualizável\", os valores de HSL foram convertidos para o intervalo $[0,255]$, de números inteiros. Então, o primeiro passo, após carregar as informações, é ajustá-las para a escala correta de representação HSL. Após feito este passo, deve-se converter a matriz HSL para RGB e gerar a imagem original reconstruída. Os passos gerais encontram-se a seguir.</p>\n",
    "\n",
    "- Carregue as informações dos canais H, S e L\n",
    "- O domínio do canal H é $[0,360]$. Para ajustá-lo, deve-se primeiro ajustar a escala para $[0,1]$ e então ajustar para o domínio de interesse ($[0,360]$):\n",
    "    - $H = \\frac{H}{255} \\cdot 360$\n",
    "- Ajuste as escalas de S e L para $[0,1]$\n",
    "- Monte a matriz $HSL$, contendo a informação ajustada de cada canal\n",
    "- Converta o resultado para RGB, usando a função que você criou no exercício anterior\n",
    "\n",
    "<p>Na célula abaixo, faça a implementação, exibindo a imagem resultante.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgR = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalH.png')\n",
    "h = np.asarray(imgR, dtype=int)\n",
    "imgG = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalS.png')\n",
    "s = np.asarray(imgG, dtype=int)\n",
    "imgB = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalL.png')\n",
    "l = np.asarray(imgB, dtype=int)\n",
    "saida=np.zeros([r.shape[0],r.shape[1],3])\n",
    "saida[:,:,0]=(h/255)*360\n",
    "saida[:,:,1]=s/255\n",
    "saida[:,:,2]=l/255\n",
    "imgS =hsl2rgb(saida)\n",
    "imgS.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Curiosidade:</b> a tamburutaca, o colorido crustáceo exibido na imagem do exercício, pertence a uma ordem de animais (<i>Stomatopoda</i>), onde algumas espécies podem ser encontradas no litoral brasileiro e possuem duas curiosidades bem peculiares. A primeira, é que estes animais possuem o mais complexo sistema de visão de cores do mundo animal, pois enxergam 12 cores primárias, correspondentes aos 12 pigmentos distintos presentes em sua retina. Para comparação, os seres humanos veem apenas 3, o RGB. A visão destes bichos possui doze cones sensíveis à luz e outros quatro que filtram a luz, podendo chegar a ver cores polarizadas e imagens multiespectrais. A outra curiosidade é que também possuem um dos mais violentos ataques do reino animal. Seu soco pode chegar à velocidade de um tiro calibre .22 (720 km/h) e uma pressão de impacto de 600 N/cm²</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Reconstrução a partir dos canais YIQ\n",
    "\n",
    "<p>A terceira reconstrução irá recriar a imagem <code>imagens/orquidea.jpg</code>. Desta vez, a partir da informação dos canais YIQ, salvas em três imagens: <code>imagens/canais/canalY.png</code>, <code>imagens/canais/canalI.png</code> e <code>imagens/canais/canalQ.png</code>.</p>\n",
    "\n",
    "<p>O modelo YIQ é um espaço de cores alternativo ao RGB. Esta tarefa consistirá em reconstruir uma imagem RGB a partir destas informações. O espaço YIQ tem um canal com informações de luminância (Y) e dois canais com informações de crominância (IQ). O domı́nio de valores para cada canal é o seguinte: $Y \\in [0, 255]$; $I \\in [−133, 133]$ e $Q \\in [−152, 152]$.</p>\n",
    "\n",
    "<p>Como no caso anterior, para que o conteúdo seja \"visualizável\", os valores de HSL foram convertidos para o intervalo $[0,255]$, de números inteiros. Então, o primeiro passo, após carregar as informações, é ajustá-las para a escala correta de representação YIQ. Os passos gerais são similares aos do caso anterior.</p>\n",
    "\n",
    "- Carregue as informações dos canais Y, I e Q\n",
    "- Ajuste as escalas de cada canal\n",
    "- Monte a matriz $YIQ$, contendo a informação ajustada de cada canal\n",
    "- Converta o resultado para RGB, criando uma função para isso\n",
    "\n",
    "<p>As conversões entre os espaços de cores são dadas por:</p>\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "Y \\\\\n",
    "I \\\\\n",
    "Q \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "T \\cdot \n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "G \\\\\n",
    "B \\\\\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "e\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "G \\\\\n",
    "B \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "T^{-1} \\cdot\n",
    "\\begin{bmatrix}\n",
    "Y \\\\\n",
    "I \\\\\n",
    "Q \\\\\n",
    "\\end{bmatrix},\\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "onde:\n",
    "\n",
    "\\begin{equation}\n",
    "T = \n",
    "\\begin{bmatrix}\n",
    "0,299 & 0,587 & 0,114 \\\\\n",
    "0,5959 & -0,2746 & -0,3213 \\\\\n",
    "0,2115 & -0,5227 & 0,3112\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "e\n",
    "\\quad\n",
    "T^{-1} = \n",
    "\\begin{bmatrix}\n",
    "1,0 & 0,956 & 0,621 \\\\\n",
    "1,0 & -0,272 & -0,647 \\\\\n",
    "1,0 & -1,107 & 1,705\n",
    "\\end{bmatrix}\n",
    "\\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "<p>Na célula abaixo, faça a <font color=\"red\">implementação das funções</font> chamadas <code>rgb2yiq</code> e <code>yiq2rgb</code>, pois usaremos estas conversões novamente mais adiante.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Você pode alterar os parâmetros da função à vontade. Só preserve o nome\n",
    "def rgb2yiq(arr):\n",
    "    T= [[0.299,0.587,0.114],\n",
    "        [0.5959,-0.2746,-0.3213],\n",
    "        [0.2115,-0.5227,0.3112]]\n",
    "    T=np.asarray(T)\n",
    "    yiq=np.dot(arr,T)\n",
    "    ajuda=yiq[:,:,0]\n",
    "    ajuda[ajuda>255]=255\n",
    "    ajuda[ajuda<0]=0\n",
    "    yiq[:,:,0]=ajuda\n",
    "    ajuda=yiq[:,:,1]\n",
    "    ajuda[ajuda>133]=133\n",
    "    ajuda[ajuda<-133]=-133\n",
    "    yiq[:,:,1]=ajuda\n",
    "    ajuda=yiq[:,:,2]\n",
    "    ajuda[ajuda>152]=152\n",
    "    ajuda[ajuda<-152]=-152\n",
    "    yiq[:,:,2]=ajuda\n",
    "    return yiq\n",
    "\n",
    "# Você pode alterar os parâmetros da função à vontade. Só preserve o nome\n",
    "def yiq2rgb(arr):\n",
    "    T =[[1.0,0.956,0.621],\n",
    "        [1.0,-0.272,-0.647],\n",
    "        [1.0,-1.107,1.705]]\n",
    "    T=np.asarray(T)\n",
    "    rgb=np.dot(arr,T)\n",
    "    ajuda=rgb[:,:,0]\n",
    "    ajuda[ajuda>255]=255\n",
    "    ajuda[ajuda<0]=0\n",
    "    rgb[:,:,0]=ajuda\n",
    "    ajuda=rgb[:,:,1]\n",
    "    ajuda[ajuda>255]=255\n",
    "    ajuda[ajuda<0]=0\n",
    "    rgb[:,:,1]=ajuda\n",
    "    ajuda=rgb[:,:,2]\n",
    "    ajuda[ajuda>255]=255\n",
    "    ajuda[ajuda<0]=0\n",
    "    rgb[:,:,2]=ajuda\n",
    "    return rgb\n",
    "    \n",
    "    # Você pode alterar o retorno da função à vontade    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na célula abaixo, crie um código que usa a função <code>yiq2rgb</code>, acima, como etapa para reconstruir a imagem em RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgR = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalY.png')\n",
    "y = np.asarray(imgR, dtype=float)\n",
    "y=y[:,:,0]\n",
    "imgG = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalI.png')\n",
    "i = np.asarray(imgG, dtype=float)\n",
    "i=i[:,:,0]\n",
    "imgB = Image.open(r'C:\\Users\\gabri\\Documents\\pdi\\trab1\\imagens\\canais\\canalQ.png')\n",
    "q = np.asarray(imgB, dtype=float)\n",
    "q=q[:,:,0]\n",
    "saida=np.zeros([y.shape[0],y.shape[1],3],dtype=float)\n",
    "saida[:,:,0]=y\n",
    "i=i/255\n",
    "i=266*i\n",
    "i=i-133\n",
    "q=q/255\n",
    "q=q*304\n",
    "q=q-152\n",
    "saida[:,:,1]=i\n",
    "saida[:,:,2]=q\n",
    "rgb=yiq2rgb(saida)\n",
    "imgS = Image.fromarray(np.uint8(rgb))\n",
    "imgS.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 Decomposição de imagem RGB em canais YIQ\n",
    "\n",
    "<p>Este exercício tem como objetivo fazer o caminho \"inverso\" do exercício anterior. A partir de uma imagem RGB convencional (<code>imagens/flores.jpg</code>), vamos convertê-la para YIQ, decompor a matriz em matrizes Y, I e Q separadas, ajustar os valores para inteiros no intervalo $[0,255]$ e produzir as visualizações de cada canal em separado, como as imagens fornecidas no exercício 3.3.3.</p>\n",
    "\n",
    "<p>Na célula abaixo, <font color=\"red\">complete o código</font> com a sua implementação, fazendo com que as imagens resultantes sejam exibidas junto com a original, no final.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/flores.jpg')\n",
    "imga=np.asarray(img)\n",
    "yiq=rgb2yiq(imga)\n",
    "imgY=yiq[:,:,0]\n",
    "imgI=yiq[:,:,1]\n",
    "imgQ=yiq[:,:,2]\n",
    "imgQ=imgQ+152\n",
    "imgQ=imgQ/304\n",
    "imgQ=imgQ*255\n",
    "imgI=imgI+133\n",
    "imgI=imgI/266\n",
    "imgI=imgI*255\n",
    "imgY=Image.fromarray(np.uint8(imgY))\n",
    "imgI=Image.fromarray(np.uint8(imgI))\n",
    "imgQ=Image.fromarray(np.uint8(imgQ))\n",
    "imgs = [img,imgY,imgI,imgQ]\n",
    "titulos = ['Imagem Original', 'Canal Y', 'Canal I', 'Canal Q']\n",
    "exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Color enhancing\n",
    "\n",
    "<p>O termo <i>Color enhancing</i> se refere a algo que pode ser mais ou menos traduzido para <i>intensificação de cor</i> ou <i>realce de cor</i>. Para este tipo de aplicação, pode ser conveniente, mais uma vez, fazer uma transformação no sistema de cores. Existem modelos que separam informação de luminsidade (luminância) da informação de cor (crominância). Um deles, é o modelo conhecido como CIE-L*a*b* (ou CIELAB), que vamos abreviar aqui apenas para L*a*b*.</p>\n",
    "\n",
    "<p>Desta vez, não vamos implementar a conversão de imagens RGB x L*a*b*, pois esta implementação tem nuances que a tornam um tanto delicada de se trabalhar. Ao invés disso, vamos usar uma implementação presente no submódulo <code>skimage.color</code>, que foi importado na primeira célula de código deste Notebook. Para converter de RGB para L*a*b*, basta fazer a chamada da função <code>color.rgb2lab</code>, informando um <i>array numpy</i> ou uma imagem <code>PIL Image</code> como parâmetro. Para a transformação no sentido inverso, a função se chama <code>color.lab2rgb</code>.</p>\n",
    "\n",
    "<p>O modelo CIELAB tem como característica trabalhar com 3 canais diferentes. O primeiro deles, o canal L*, traz informação exclusivamente de luminância da imagem, com valores $L^{*} \\in [0,100]$. O segundo canal, a*, traz informação de cor em um eixo que vai do verde (valores negativos) ao vermelho (valores positivos). Na implementação do módulo <code>skimage</code>, $a^{*} \\in [-86.183, 98.233]$. O terceiro canal, b*, traz informação de cor em um eixo que vai do azul (valores negativos) ao amarelo (valores positivos). Na implementação do módulo <code>skimage</code>, $b^{*} \\in [-107.857,94.478]$.</p>\n",
    "\n",
    "<p>Estes valores \"quebrados\" se devem aos detalhes de implementação mencionados, mas cobrem as cores perceptíveis para o ser humano. Outro detalhe importante é que, se duranto o uso de uma das funções, um <i>warning</i> do tipo: <code>UserWarning: Color data out of range</code> surgir, não se preocupe. É apenas um aviso de que algumas cores sofrerão uma \"poda\" para os intervalos ilustrados acima. Você pode ignorá-los.</p>\n",
    "\n",
    "<p>O espaço CIELAB tem como principal característica organizar as cores de acordo com a maneira que os seres humanos percebem as similaridades entre as mesmas, portanto é muito utilizado em várias aplicações onde medir a semelhança entre cores é importante. Vamos utilizar a conversão para este sistema novamente mais à frente, em outros exercícios.</p>\n",
    "\n",
    "<p>Para a aplicação do <i>color enhancing</i>, <font color=\"red\">Complete o código da função</font> <code>color_enhance</code> abaixo, de acordo com os seguintes passos:</p>\n",
    "\n",
    "- Converta a imagem <code>img</code> para CIELAB, gerando uma matriz $LAB$\n",
    "- Vamos alargar o contraste da imagem, porém apenas operando sobre a luminância. Alargue o contraste do canal $L^{*}$, só que ao invés de trabalhar com o intervalo $[0,255]$, adapte para o intervalo $[0,100]$.\n",
    "- Aplique o fator de ajuste <code>fatorA</code> ao canal a*:\n",
    "    - $a^{*} \\leftarrow a^{*} \\cdot \\mathrm{fatorA}$\n",
    "- Aplique o fator de ajuste <code>fatorB</code> ao canal b*:\n",
    "    - $b^{*} \\leftarrow b^{*} \\cdot \\mathrm{fatorB}$\n",
    "- Faça a poda dos valores de cada canal para os intervalos de domínio descritos no enunciado\n",
    "- Converta $LAB$ de volta para RGB, gerando uma matriz $RGB$. Os valores retornados pela função serão $RGB \\in [0,1]$. Ajuste-os para $[0,255]$, lembrando-se de arredondar os resultados.\n",
    "- Retorne um obeto <code>PIL Image</code> como resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alargaContrastelab(img,limiteL=100):\n",
    "    f=np.asarray(img)\n",
    "    n=np.empty(f.shape,dtype=float)\n",
    "    n=((f-np.min(f))/(np.max(f)-np.min(f)))*limiteL\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return n\n",
    "\n",
    "def color_enhance(img, fatorA=2.5, fatorB=2.5, limiteL=100):\n",
    "    img=np.asarray(img,dtype=float)\n",
    "    img=img/255\n",
    "    lab=color.rgb2lab(img)\n",
    "    lab[:,:,0]=alargaContrastelab(lab[:,:,0],limiteL)\n",
    "    lab[:,:,1]=lab[:,:,1]*fatorA\n",
    "    ajuda=lab[:,:,1]\n",
    "    ajuda[ajuda<-86.183]=-86.183\n",
    "    ajuda[ajuda>98.233]=98.233\n",
    "    lab[:,:,1]=ajuda\n",
    "    lab[:,:,2]=lab[:,:,2]*fatorB\n",
    "    ajuda=lab[:,:,2]\n",
    "    ajuda[ajuda<-107.857]=-107.857\n",
    "    ajuda[ajuda>94.478]=94.478\n",
    "    lab[:,:,2]=ajuda\n",
    "    enh=color.lab2rgb(lab)\n",
    "    enh=Image.fromarray(np.uint8(255*enh))\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return enh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo para testar sua implementação da função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/capivara.jpg')\n",
    "\n",
    "fatoresA = [0.5, 1, 1.5, 2, 2.5]\n",
    "fatoresB = [0.5, 1, 1.5, 2, 2.5]\n",
    "\n",
    "imagens = [img]\n",
    "titulos = ['Original']\n",
    "\n",
    "for fatorA in fatoresA:\n",
    "    for fatorB in fatoresB:\n",
    "        imgEnh = color_enhance(img, fatorA, fatorB, 100)\n",
    "        imagens.append(imgEnh)\n",
    "        titulo = 'Fator A: %.1f, Fator B: %.1f' % (fatorA, fatorB)\n",
    "        titulos.append(titulo)\n",
    "        \n",
    "exibe_bloco(imagens, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo para testar sua implementação da função versus outras técnicas de tratamento de cores\n",
    "\n",
    "<p>Suas implementações das funções <code>alargaContraste</code> e <code>satura</code> são utilizadas aqui.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arquivos = [\n",
    "    'imagens/praiaRuim.png',\n",
    "    'imagens/praiaOrig.png',\n",
    "    'imagens/capivara.jpg',\n",
    "    'imagens/foto_antiga01.jpg'\n",
    "]\n",
    "# Tanto color_enhance quanto satura estão sendo testados para níveis altos de ajuste\n",
    "for arquivo in arquivos:\n",
    "    img = abre_imagem(arquivo)\n",
    "    imgEnh = color_enhance(img, 2.5, 2.5, 100)\n",
    "    fator_sat = 2\n",
    "    ####### SE NECESSÁRIO, ADAPTE AS 2 FUNÇÕES ABAIXO PARA COMPATIBILIZAR COM SEU CÓDIGO #######\n",
    "    imgSat = satura(img, fator_sat)\n",
    "    imgAlarg = alargaContraste(img)\n",
    "\n",
    "    imagens = [img, imgAlarg, imgSat, imgEnh]\n",
    "    titulos = ['Original', 'Alargamento de Contraste', 'Saturada com fator %.1f' % fator_sat, 'Color Enhancement']\n",
    "\n",
    "    exibe_bloco(imagens, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Ranqueando imagens por cor\n",
    "\n",
    "<p>Esta atividade é bem simples. Queremos gerar um ranking de visualização de <i>thumbnails</i> (miniaturas) de todas as imagens contidas na pasta <code>imagens/</code>, mas não sobre suas subpastas. Para isto, vamos utilizar uma métrica chamada <i>colorfulness</i> que estima o quanto uma imagem é colorida, de acordo com a percepção humana. Quanto maior o valor da métrica, mais colorida é a imagem.</p>\n",
    "\n",
    "<p>A maior parte do código já se encontra pronto na célula abaixo. Há uma função que gera as miniaturas (<code>gera_thumb</code>) e uma rotina principal, que percorre todos arquivos da pasta de imagens (mas não as subpastas), identifica quais delas são imagens, gera o <i>thumbnail</i> de cada uma, calcula a <i>colorfulness</i> e as ordena de acordo com a métrica, de forma decrescente. Por fim, uma visualização do ranking é gerada e exibida em tela.</p>\n",
    "\n",
    "<p>Cabe a você <font color=\"red\">implementar o corpo</font> da função <code>colorfulness</code>, que receberá um <i>array numpy</i> contendo os dados de uma imagem e retornará a métrica, calculada como a seguir:</p>\n",
    "\n",
    "- $R$, $G$ e $B \\leftarrow$ matrizes dos canais RGB do array de entrada\n",
    "- $RG \\leftarrow |R - G|$\n",
    "- $YB \\leftarrow |(R + G) \\cdot 0,5 - B|$\n",
    "- $\\mu \\leftarrow \\sqrt{\\mu_{RG}^{2} + \\mu_{YB}^{2}}$, onde:\n",
    "    - $\\mu_{RG}^{2}$ é a média dos valores em $RG$\n",
    "    - $\\mu_{YB}^{2}$ é a média dos valores em $YB$\n",
    "- $\\sigma \\leftarrow \\sqrt{\\sigma_{RG}^{2} + \\sigma_{YB}^{2}}$, onde:\n",
    "    - $\\sigma_{RG}^{2}$ é o desvio padrão em $RG$\n",
    "    - $\\sigma_{YB}^{2}$ é o desvio padrão em $YB$\n",
    "- Retorne o resultado de $\\sigma + 0,3 \\cdot \\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def colorfulness(arr):\n",
    "    RG=abs(arr[:,:,0]-arr[:,:,1])\n",
    "    YB=abs(0.5*(arr[:,:,0]+arr[:,:,1])-arr[:,:,2])\n",
    "    u=math.sqrt(np.mean(RG)**2 + np.mean(YB)**2)\n",
    "    o=math.sqrt(np.std(RG)**2 + np.std(YB)**2)\n",
    "    c=o+0.3*u\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return c\n",
    "\n",
    "def gera_thumb(img, tam_base=64):\n",
    "    maior = max(img.width, img.height)\n",
    "    fator = tam_base/maior\n",
    "    h = int(round(img.height * fator))\n",
    "    w = int(round(img.width * fator))\n",
    "    return img.resize((w,h))\n",
    "\n",
    "pasta = 'imagens/'\n",
    "imgs = []\n",
    "titulos = []\n",
    "ranking = []\n",
    "for a in os.listdir(pasta):\n",
    "    arq = pasta + a\n",
    "    if os.path.isfile(arq) and imghdr.what(arq) is not None:\n",
    "        img = Image.open(arq)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        th = gera_thumb(img, tam_base=128)\n",
    "        c = colorfulness(np.asarray(img, dtype=float))\n",
    "        i = 0\n",
    "        while i < len(imgs):\n",
    "            if c < ranking[i]:\n",
    "                break\n",
    "            i += 1\n",
    "        ranking.insert(i, c)\n",
    "        imgs.insert(i, th)\n",
    "        titulos.insert(i, '%s\\ncolorfulness = %8.3f' % (a,c))\n",
    "        print(a, '%8.3f' % c)\n",
    "\n",
    "print('Encontrado um total de %d imagens.' % len(imgs))\n",
    "tam_linha = 8\n",
    "\n",
    "exibe_bloco(imgs, titulos, tam_linha=tam_linha, dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parte III: operações ponto-a-ponto\n",
    "\n",
    "### 4.1 Implementando o filtro \"destaque de cor\"\n",
    "\n",
    "<p>Em aula, foi visto um exemplo de um filtro que foi chamado de \"destaque de cor\". Iremos revisitar este exemplo, com algumas modificações. No exemplo de aula, foi usado o espaço de cores chamado HSV. Aqui, no entanto, vamos utilizar, mais uma vez, o CIELAB.</p>\n",
    "\n",
    "<p>A ideia do filtro é, dada uma imagem colorida $img$, uma cor de referência $ref$ e um grau de tolerância $\\epsilon$, gerar uma imagem $destaque$, com as seguintes características. Os pixels $px$, em $img$, onde a distância de sua cor ($c_{px}$) para $ref$ for maior que um limiar $\\delta$ (calculado a partir de $\\epsilon$), serão copiados para $destaque$ em sua versão em tons de cinza. Os pixels $px$, onde $\\textrm{dist}(c_{px}, ref) \\leq \\delta$, serão copiados para $destaque$ em sua versão colorida. Se o parâmetro $inv$ for informado como verdadeiro, esta lógica deve ser invertida, isto é, os pixels que seriam copiados como cinza, serão copiados como colorido e vice-versa.</p>\n",
    "\n",
    "<p>Para calcular a distância entre cores, converta tanto a cor de referência $ref$, quanto a imagem $img$ para CIELAB, usando a mesma função utilizada anteriormente. A distância utilizada, uma vez neste espaço de cores, pode ser a distância euclidiana convencional.</p>\n",
    "\n",
    "<p>O limiar $\\delta$ pode ser calculado a partir de $\\epsilon$, usado como um percentual da maior distância entre um pixel $px_{lab}$ da imagem em CIELAB para a cor de referência também na versão CIELAB: $ref_{lab}$. Ou seja: $\\delta \\leftarrow \\epsilon \\cdot \\textrm{máximo}(\\textrm{dist}(px_{lab}, ref_{lab}))$</p>\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>destaqueCor</code> abaixo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destaqueCor(img, ref, epsilon=0.1, inv=False):\n",
    "    img=np.asarray(img,dtype=float)\n",
    "    ref=np.asarray(ref,dtype=float)\n",
    "    cinza=color.rgb2gray(img)\n",
    "    cinza=color.gray2rgb(cinza)\n",
    "    imglab=color.rgb2lab(img)\n",
    "    reflab=color.rgb2lab(ref)\n",
    "    arref=np.empty_like(img)\n",
    "    arref[:,:,:]=reflab\n",
    "    dist = np.linalg.norm(imglab-arref,axis=2)\n",
    "    e=epsilon*np.max(dist)\n",
    "    destaque=np.empty_like(img)\n",
    "    if inv:\n",
    "        destaque[dist<=e]=cinza[dist<=e]\n",
    "        destaque[dist>e]=img[dist>e]\n",
    "    else:\n",
    "        destaque[dist<=e]=img[dist<=e]\n",
    "        destaque[dist>e]=cinza[dist>e]\n",
    "    destaque=Image.fromarray(np.uint8(destaque))\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return destaque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute as próximas <u>três</u> células a seguir para testar seu código\n",
    "\n",
    "<p>Caso deseje testar com outras imagens ou cores de referência, você pode usar um software de edição de imagens como o GIMP ou Photoshop para obter a cor de um determinado pixel. A ferramenta para isto é comumente chamada \"seleção de cor\" e costuma ser representada por um ícone de conta gotas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/ipe2.jpg')\n",
    "# Amarelo\n",
    "cor1 = np.array([[[234, 174, 2]]])\n",
    "# Azul\n",
    "cor2 = np.array([[[32, 67, 121]]])\n",
    "# Marrom\n",
    "cor3 = np.array([[[107,67,55]]])\n",
    "\n",
    "cores = [cor1, cor2, cor3, cor1]\n",
    "epsilons = [0.4, 0.3, 0.25, 0.4]\n",
    "inversoes = [False, False, False, True]\n",
    "\n",
    "imgs = [img]\n",
    "titulos = ['Original']\n",
    "for i,cor in enumerate(cores):\n",
    "    imgDest = destaqueCor(img, cor, epsilon=epsilons[i], inv=inversoes[i])\n",
    "    imgs.append(imgDest)\n",
    "    corStr = ', '.join([str(c) for c in cor[0,0]])\n",
    "    if inversoes[i]:\n",
    "        invStr = '\\nCom Inversão de Resultado'\n",
    "    else:\n",
    "        invStr = ''\n",
    "    titulos.append('Destaque para cor (%s) e tolerância %.2f%s' % (corStr, epsilons[i], invStr))\n",
    "    \n",
    "exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/flores_vermelhas.jpg')\n",
    "# Vermelho escuro\n",
    "cor1 = np.array([[[120, 21, 42]]])\n",
    "# Rosado\n",
    "cor2 = np.array([[[200, 73, 116]]])\n",
    "# Verde\n",
    "cor3 = np.array([[[108, 122, 87]]])\n",
    "# Azul\n",
    "cor4 = np.array([[[104, 140, 190]]])\n",
    "\n",
    "cores = [cor1, cor2, cor3, cor4, cor4]\n",
    "epsilons = [0.4, 0.4, 0.4, 0.2, 0.2]\n",
    "inversoes = [False, False, False, False, True]\n",
    "\n",
    "imgs = [img]\n",
    "titulos = ['Original']\n",
    "for i,cor in enumerate(cores):\n",
    "    imgDest = destaqueCor(img, cor, epsilon=epsilons[i], inv=inversoes[i])\n",
    "    imgs.append(imgDest)\n",
    "    corStr = ', '.join([str(c) for c in cor[0,0]])\n",
    "    if inversoes[i]:\n",
    "        invStr = '\\nCom Inversão de Resultado'\n",
    "    else:\n",
    "        invStr = ''\n",
    "    titulos.append('Destaque para cor (%s) e tolerância %.2f%s' % (corStr, epsilons[i], invStr))\n",
    "    \n",
    "exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/fitas_bonfim.jpg')\n",
    "# Azul escuro\n",
    "cor1 = np.array([[[29, 24, 88]]])\n",
    "# Azul claro\n",
    "cor2 = np.array([[[137, 174, 226]]])\n",
    "# Amarelo\n",
    "cor3 = np.array([[[255, 247, 30]]])\n",
    "# Vermelho\n",
    "cor4 = np.array([[[227, 34, 37]]])\n",
    "# Verde\n",
    "cor5 = np.array([[[43, 130, 35]]])\n",
    "\n",
    "cores = [cor1, cor2, cor3, cor5, cor4, cor4, cor4, cor4, cor4, cor4, cor4]\n",
    "epsilons = [0.3, 0.3, 0.4, 0.4, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "inversoes = [False, False, False, False, False, False, False, False, False, False, False]\n",
    "\n",
    "imgs = [img]\n",
    "titulos = ['Original']\n",
    "for i,cor in enumerate(cores):\n",
    "    imgDest = destaqueCor(img, cor, epsilon=epsilons[i], inv=inversoes[i])\n",
    "    imgs.append(imgDest)\n",
    "    corStr = ', '.join([str(c) for c in cor[0,0]])\n",
    "    if inversoes[i]:\n",
    "        invStr = '\\nCom Inversão de Resultado'\n",
    "    else:\n",
    "        invStr = ''\n",
    "    titulos.append('Destaque para cor (%s) e tolerância %.2f%s' % (corStr, epsilons[i], invStr))\n",
    "    \n",
    "exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Combinação Linear com Coeficientes Variáveis\n",
    "\n",
    "<p>Conforme visto em aula, pode-se utilizar uma função $\\alpha(y,x) \\in [0,1]$, cujos valores variam com as coordenadas (y,x) (ou (x,y)) da imagem, para que se determine dinamicamente os coeficientes de uma combinação linear entre duas imagens. Sendo $f(y,x)$ e $g(y,x)$ as imagens de entrada (<b>de mesmas dimensões e tamanhos</b>) e $h(y,x)$ a imagem de saída, a ideia é combinar $f$ e $g$ da seguinte forma: $h(y,x) = \\alpha(y,x) \\cdot f(y,x) + (1 - \\alpha(y,x)) \\cdot g(y,x)$</p>\n",
    "\n",
    "<p>Para simplificar, vamos fazer uma versão de $\\alpha$ que varie apenas de acordo com as colunas da imagem, isto é, teremos uma função $\\alpha(x)$ apenas. Sendo assim, trabalharemos com:</p>\n",
    "\n",
    "<p style=\"text-align: center\">$h(y,x) = \\alpha(x) \\cdot f(y,x) + (1 - \\alpha(x)) \\cdot g(y,x)$</p>\n",
    "\n",
    "<p>Em outras palavras, cada pixel em $h(y,x)$ será uma combinação, em cada canal RGB, de uma parcela do pixel na mesma posição em $f(y,x)$ e de uma parcela naquela mesma posição em $g(y,x)$. A parcela que será obtida de cada pixel dependerá de qual coluna estamos, pois $\\alpha(x)$ varia os valores de acordo com $x$. Em um exemplo hipotético, $h$, na posição $(2,3)$, poderia ser $h(2,3) = 0,21 \\cdot f(2,3) + 0,79 \\cdot g(2,3)$, enquanto na posição $(2,9)$, poderia ser $h(2,9) = 0,44 \\cdot f(2,9) + 0,56 \\cdot g(2,9)$, pois estamos em outra posição de $x$, em relação a $(2,3)$. Já em $(7,3)$, poderia ser $h(7,3) = 0,21 \\cdot f(7,3) + 0,79 \\cdot g(7,3)$, com os mesmos pesos de $(2,3)$, já que compartilham a mesma posição em $x$.</p>\n",
    "\n",
    "<p>Desta forma, este exercício consiste em combinar duas imagens para gerar uma terceira como nos dois exemplos abaixo:</p>\n",
    "\n",
    "<img src=\"imagens/exemplos/ufv_dia_noite.png\" width=\"100%\">\n",
    "\n",
    "<img src=\"imagens/exemplos/rapaz_moca.png\" width=\"50%\">\n",
    "\n",
    "<p>Estas imagens foram geradas utilizando uma função sigmoide da seguinte forma:</p>\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha(x) = 1 - 0,5 \\cdot \\left[1 -\\frac{\\textrm{arctan}(a\\cdot x - \\frac{a}{2})}{\\textrm{arctan}(\\frac{-a}{2})} \\right],\n",
    "\\end{equation}\n",
    "\n",
    "<p>onde $a$ é um parâmetro que controla o quão gradual ou brusca deve ser transição de pesos, como nos exemplos abaixo.</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"imagens/exemplos/alfa_a_1.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imagens/exemplos/alfa_a_10.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imagens/exemplos/alfa_a_30.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imagens/exemplos/alfa_a_50.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"4\"><img src=\"imagens/exemplos/comblin.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo da função</font> <code>combina</code>, que recebe duas imagens, um valor de $a$ e retorna a combinação linear conforme descrita acima, usando a mesma função sigmoide utilizada para gerar os exemplos.</p>\n",
    "\n",
    "<p>Implemente, também, <font color=\"red\">o corpo da função</font> <code>espelha</code>, que recebe uma imagem e retorna esta mesma imagem espelhada horizontalmente, isto é, a primeira coluna troca de lugar com a última, a segunda com a antepenúltima e assim por diante. Esta função é utilizada no trecho de código de teste abaixo para gerar imagens com as duas metades esquerdas e as duas metades direitas da pessoa combinadas espelhadamente.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def espelha(img):\n",
    "    espelho=np.asarray(img)\n",
    "    copia=np.copy(espelho)\n",
    "    for x in range(espelho.shape[0]):\n",
    "        Y=espelho.shape[1]-1\n",
    "        for y in range(espelho.shape[1]):\n",
    "            espelho[x][y]=copia[x][Y]\n",
    "            Y-=1\n",
    "    \n",
    "    # Você pode alterar o retorno da função à vontade\n",
    "    espelho=Image.fromarray(np.uint8(espelho))\n",
    "    return espelho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combina(imgEsq, imgDir, a=50):\n",
    "    f=np.asarray(imgEsq,dtype=float)\n",
    "    g=np.asarray(imgDir,dtype=float)\n",
    "    h = np.empty(f.shape, dtype=float)\n",
    "    for x in range(f.shape[1]):\n",
    "        num=np.arctan(a*(x/f.shape[1])-a/2)\n",
    "        den=np.arctan(-a/2)\n",
    "        alfa=1-0.5*(1-(num/den))\n",
    "        h[:,x,:]=alfa*f[:,x,:]+(1-alfa)*g[:,x,:]\n",
    "    comb=Image.fromarray(np.uint8(h))\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo para testar suas implementações das funções <code>espelha</code> e <code>combina</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgDir = abre_imagem('imagens/ufv_dia.jpg')\n",
    "imgEsq = abre_imagem('imagens/ufv_noite.jpg')\n",
    "a = 50\n",
    "imgMerge = combina(imgEsq, imgDir,a)\n",
    "exibe_bloco([imgEsq,imgDir,imgMerge], ['Lado esquerdo', 'Lado direito', 'Combinação (a=%.1f)'%a])\n",
    "\n",
    "a = 40\n",
    "imgBase = abre_imagem('imagens/moca.jpg')\n",
    "imgEspelho = espelha(imgBase)\n",
    "\n",
    "imgMerge2 = combina(imgBase,imgEspelho,a)\n",
    "exibe_bloco([imgBase,imgEspelho,imgMerge2], ['Original', 'Espelhada', 'Duas metades esquerdas (a=%.1f)'%a])\n",
    "\n",
    "imgMerge3 = combina(imgEspelho,imgBase, a)\n",
    "exibe_bloco([imgEspelho,imgBase,imgMerge3], ['Espelhada', 'Original', 'Duas metades direitas (a=%.1f)'%a])\n",
    "\n",
    "a = 50\n",
    "imgEsq = abre_imagem('imagens/rapaz2.jpg')\n",
    "imgDir = abre_imagem('imagens/moca2.jpg')\n",
    "imgMerge4 = combina(imgEsq, imgDir,a)\n",
    "exibe_bloco([imgEsq,imgDir,imgMerge4], ['Rapaz', 'Moça', 'Combinação (a=%.1f)'%a])\n",
    "\n",
    "imgEsq = abre_imagem('imagens/moca2.jpg')\n",
    "imgDir = abre_imagem('imagens/rapaz2.jpg')\n",
    "imgMerge4 = combina(imgEsq, imgDir,a)\n",
    "exibe_bloco([imgEsq,imgDir,imgMerge4], ['Moça', 'Rapaz', 'Combinação (a=%.1f)'%a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parte IV: histogramas\n",
    "\n",
    "### 5.1 Gerando e plotando histogramas\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>_histograma</code> abaixo (o nome começa com um <i>underline</i> mesmo), que recebe como parâmetros:</p>\n",
    "- O <i>array numpy</i> <code>arr</code>, contendo dados de uma imagem\n",
    "- A string <code>tipo</code>, informando o tipo de histograma que será gerado:\n",
    "    - <code>'h'</code> indica que será gerado um histograma convencional da imagem, com as contagens de pixel por tom (de cinza ou de um determinado canal RGB)\n",
    "    - <code>'p'</code> indica que será gerado um histograma de probabilidades da imagem\n",
    "    - <code>'cdf'</code> indica que será gerado um histograma de distribuição de probabilidades acumuladas da imagem\n",
    "- O inteiro <code>L</code>, informando o número de tons que o <i>array</i> possui. Tipicamente, 256.\n",
    "\n",
    "<p>A função deve retornar um <i>array numpy</i> contendo o histograma pedido</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _histograma(f, tipo, L):\n",
    "    if tipo == 'h':\n",
    "        h = np.zeros(L)\n",
    "        for k in range(L):\n",
    "            h[k] = np.sum(f == k)\n",
    "        return h\n",
    "    elif tipo == 'p':\n",
    "        h = np.zeros(L)\n",
    "        for k in range(L):\n",
    "            h[k] = np.sum(f == k)\n",
    "        return h/(f.shape[0] * f.shape[1])\n",
    "    elif tipo == 'cdf':\n",
    "        h = np.zeros(L)\n",
    "        for k in range(L):\n",
    "            h[k] = np.sum(f == k)\n",
    "        p=h/(f.shape[0] * f.shape[1])\n",
    "        cdf = np.zeros(p.shape)\n",
    "        for k in range(len(p)):\n",
    "            cdf[k] = np.sum(p[:k+1])\n",
    "        return cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções prontas\n",
    "\n",
    "<p>A função <code>histogramas</code> abaixo recebe os mesmos parâmetros da função que você implementou na célula acima. Ela faz os seguintes passos:</p>\n",
    "\n",
    "- Verifica se a imagem recebida é em tons de cinza ou colorida\n",
    "    - Se cinza, apenas chama a função <code>_histograma</code>, repassando os parâmetros e retorna sua resposta\n",
    "    - Se colorida, cria um array de saída (<code>out</code>), de dimensões $4\\times L$, onde cada linha receberá um histograma:\n",
    "        - Posição 0: histograma da versão em cinza da imagem\n",
    "        - Posição 1: histograma do canal R\n",
    "        - Posição 2: histograma do canal G\n",
    "        - Posição 3: histograma do canal B\n",
    "        \n",
    "<p>A função <code>plota_histogramas</code> abaixo abaixo recebe os mesmos parâmetros da função anterior, executa a função <code>histogramas</code> e plota em tela seus resultados</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramas(img, tipo='h', L=256):\n",
    "    arr = np.asarray(img)\n",
    "    \n",
    "    if len(arr.shape) == 2:\n",
    "        return _histograma(arr, tipo, L)\n",
    "    else:\n",
    "        out = np.empty((4,L))\n",
    "        cinza = np.round(0.299 * arr[:,:,0] + 0.587 * arr[:,:,1] + 0.114 * arr[:,:,2])\n",
    "        out[0,:] = _histograma(cinza, tipo, L)\n",
    "        for c in range(1,4):\n",
    "            out[c,:] = _histograma(arr[:,:,c-1], tipo, L)\n",
    "        return out\n",
    "\n",
    "def plota_histogramas(img, tipo='h', L=256):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    tipos = {\n",
    "        'h': 'Convencionais',\n",
    "        'p': 'de Probabilidades',\n",
    "        'cdf': 'de Distr. de Prob. Acumuladas'\n",
    "    }\n",
    "    fig.suptitle('Histogramas ' + tipos[tipo])\n",
    "    \n",
    "    out = histogramas(img, tipo, L)\n",
    "    \n",
    "    k = np.array(list(range(L)))\n",
    "    \n",
    "    # Imagem\n",
    "    ax = fig.add_subplot(2,3,1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Imagem')\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Histograma da Imagem Cinza\n",
    "    ax = fig.add_subplot(2, 3, 2)\n",
    "    ax.bar(k, out[0], color='gray')\n",
    "    ax.set_xlim(0,L-1)\n",
    "    ax.set_title('Tons de Cinza')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Histograma do Canal R\n",
    "    ax = fig.add_subplot(2, 3, 4)\n",
    "    ax.bar(k, out[1], color='red')\n",
    "    ax.set_xlim(0,L-1)\n",
    "    ax.set_title('Canal R')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Histograma do Canal G\n",
    "    ax = fig.add_subplot(2, 3, 5)\n",
    "    ax.bar(k, out[2], color='green')\n",
    "    ax.set_xlim(0,L-1)\n",
    "    ax.set_title('Canal G')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Histograma da Imagem Cinza\n",
    "    ax = fig.add_subplot(2, 3, 6)\n",
    "    ax.bar(k, out[3], color='blue')\n",
    "    ax.set_xlim(0,L-1)\n",
    "    ax.set_title('Canal B')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo para testar sua implementação\n",
    "\n",
    "<p>Você deve ver os histogramas da imagem, juntamente com a mesma</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = abre_imagem('imagens/capivara.jpg')\n",
    "plota_histogramas(img, tipo='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Equalização de histogramas\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>equaliza</code> abaixo, que recebe como parâmetro uma imagem e faz a equalização de histograma da mesma, conforme ensinado em aula.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equaliza(img):\n",
    "    Lmax = 255\n",
    "    f=np.asarray(img)\n",
    "    CDFr = _histograma(f[:,:,0],'cdf',256)\n",
    "    CDFg = _histograma(f[:,:,1],'cdf',256)\n",
    "    CDFb = _histograma(f[:,:,2],'cdf',256)\n",
    "    CDF=np.array([CDFr,CDFg,CDFb])\n",
    "    L = Lmax + 1\n",
    "    s=np.zeros((3,L),np.uint8)\n",
    "    for k in range(0,L):\n",
    "        s[:,k]=np.uint8(np.round(Lmax*CDF[:,k]))\n",
    "    imgEq=img.copy()\n",
    "    for y in range (imgEq.height):\n",
    "        for x in range(imgEq.width):\n",
    "            r,g,b=imgEq.getpixel((x,y))\n",
    "            r=s[0,r]\n",
    "            g=s[1,g]\n",
    "            b=s[2,b]\n",
    "            imgEq.putpixel((x,y),(r,g,b))   \n",
    "    return imgEq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute o código abaixo para testar sua implementação\n",
    "\n",
    "<p>A execução pode demorar um tempo. A função <code>alargaContraste</code>, que você implementou anteriormente, será utilizada aqui.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = []\n",
    "arquivos.append('imagens/praiaRuim.png')\n",
    "arquivos.append('imagens/praiaRuim2.png')\n",
    "arquivos.append('imagens/texto_1.jpg')\n",
    "arquivos.append('imagens/texto_2.jpg')\n",
    "arquivos.append('imagens/texto_sombra.jpg')\n",
    "arquivos.append('imagens/mar_salvador02.jpg')\n",
    "arquivos.append('imagens/ufv-estourada.jpg')\n",
    "arquivos.append('imagens/pousada-estourada.png')\n",
    "for arquivo in arquivos:\n",
    "    img = abre_imagem(arquivo)\n",
    "    imgAlarg = alargaContraste(img)\n",
    "    imgEq = equaliza(img)\n",
    "    exibe_bloco([img, imgAlarg, imgEq], ['Original', 'Alargamento de Constraste', 'Equalização de Histograma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Transferência de estilos entre imagens\n",
    "\n",
    "#### 5.3.1 Especificação direta de histogramas\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>especificacao_direta</code> abaixo, que recebe como parâmetros uma imagem alvo, que fornecerá as formas do resultado final e receberá o estilo, e uma imagem que fornecerá o estilo de cores para a primeira. A função deve retornar o resultado da especificação direta de histogramas, conforme visto em aula.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def especificacao_direta(imgAlvo, imgEstilo):\n",
    "    f=np.asarray(imgAlvo)\n",
    "    g=np.asarray(imgEstilo)\n",
    "    CDFr = _histograma(f[:,:,0],'cdf',256)\n",
    "    CDFg = _histograma(f[:,:,1],'cdf',256)\n",
    "    CDFb = _histograma(f[:,:,2],'cdf',256)\n",
    "    CDFf=np.array([CDFr,CDFg,CDFb])\n",
    "    CDFr = _histograma(g[:,:,0],'cdf',256)\n",
    "    CDFg = _histograma(g[:,:,1],'cdf',256)\n",
    "    CDFb = _histograma(g[:,:,2],'cdf',256)\n",
    "    CDFg=np.array([CDFr,CDFg,CDFb])\n",
    "    mapa=np.zeros((3,256),dtype=np.uint8)\n",
    "    for k in range (256):\n",
    "        for canal in range(3):\n",
    "            dist=np.abs(CDFf[canal,k]-CDFg[canal,:])\n",
    "            mapa[canal,k]=np.argmin(dist)\n",
    "    imgEspec=imgAlvo.copy()\n",
    "    for y in range (imgEspec.height):\n",
    "        for x in range(imgEspec.width):\n",
    "            r,g1,b=imgEspec.getpixel((x,y))\n",
    "            R=mapa[0,r]\n",
    "            G=mapa[1,g1]\n",
    "            B=mapa[2,b]\n",
    "            imgEspec.putpixel((x,y),(R,G,B))   \n",
    "    return imgEspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo para testar seu código\n",
    "\n",
    "<p>Execução pesada, pode levar um tempo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pares = []\n",
    "pares.append(['imagens/mar_salvador02.jpg', 'imagens/mar_salvador01.jpg'])\n",
    "pares.append(['imagens/capivara.jpg', 'imagens/grilo.jpg'])\n",
    "pares.append(['imagens/hindu.jpg', 'imagens/favela.jpg'])\n",
    "pares.append(['imagens/capivara_cinza.jpg', 'imagens/foto_antiga01.jpg'])\n",
    "for par in pares:\n",
    "    imgAlvo = abre_imagem(par[0])\n",
    "    imgEstilo = abre_imagem(par[1])\n",
    "    imgEspec = especificacao_direta(imgAlvo, imgEstilo)\n",
    "    imgs = [imgAlvo,imgEstilo,imgEspec]\n",
    "    titulos = ['Imagem Alvo', 'Imagem com Estilo', 'Especificação Direta']\n",
    "    exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 <i>Fast transfer</i>\n",
    "\n",
    "<p>Uma forma alternativa de se transferir estilos entre imagens é o que chamaremos informalmente aqui de <i>fast transfer</i>, pois a técnica não tem um nome específico.</p>\n",
    "\n",
    "<p>A técnica consiste em usar o desvio padrão e a média das cores das imagens de alvo e estilo para que se faça com que o histograma da imagem alvo \"se pareça\" com o da imagem de estilo. Para que o resultado fique visualmente bom, é interessante que usemos um espaço de cores que leva em conta a percepção humana, como o CIELAB. Sendo assim, vamos novamente trabalhar com imagens convertidas para este modelo de cores.</p>\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>fast_transfer</code> abaixo, que recebe como parâmetros uma imagem alvo, que fornecerá as formas do resultado final e receberá o estilo, e uma imagem que fornecerá o estilo de cores para a primeira. A função deve retornar o resultado da aplicação da técnica descrita a seguir.</p>\n",
    "\n",
    "- Converta <code>imgAlvo</code> para CIELAB, gerando $a$\n",
    "- Converta <code>imgEstilo</code> para CIELAB, gerando $e$\n",
    "- Em cada canal $c$, de $a$, faça:\n",
    "    - $a_{c} \\leftarrow (\\sigma_{c}^{e}/\\sigma_{c}^{a}) \\cdot (a_{c} - \\mu_{c}^{a}) + \\mu_{c}^{e}$\n",
    "    - onde:\n",
    "        - $\\mu_{c}^{a}$ é a média dos valores do canal $c$ em $a$\n",
    "        - $\\mu_{c}^{e}$ é a média dos valores do canal $c$ em $e$\n",
    "        - $\\sigma_{c}^{a}$ é o desvio padrão dos valores do canal $c$ em $a$\n",
    "        - $\\sigma_{c}^{e}$ é o desvio padrão dos valores do canal $c$ em $e$\n",
    "- Converta $a$ para RGB, gerando $saida$\n",
    "- Ajuste a escala da imagem resultante: $saida \\leftarrow saida \\cdot 255$\n",
    "- Arredonde a saída para valores inteiros e gere uma imagem <code>PIL Image</code>\n",
    "- Retorne a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_transfer(imgAlvo, imgEstilo):\n",
    "    a=np.asarray(imgAlvo)\n",
    "    e=np.asarray(imgEstilo)\n",
    "    a=color.rgb2lab(a)\n",
    "    e=color.rgb2lab(e)\n",
    "    for c in range(3):\n",
    "        a[:,:,c]=(np.std(e[:,:,c])/np.std(a[:,:,c]))*(a[:,:,c]-np.mean(a[:,:,c]))+np.mean(e[:,:,c])\n",
    "    ajuda=a[:,:,1]\n",
    "    ajuda[ajuda<-86.183]=-86.183\n",
    "    ajuda[ajuda>98.233]=98.233\n",
    "    a[:,:,1]=ajuda\n",
    "    ajuda=a[:,:,2]\n",
    "    ajuda[ajuda<-107.857]=-107.857\n",
    "    ajuda[ajuda>94.478]=94.478\n",
    "    a[:,:,2]=ajuda\n",
    "    ajuda=a[:,:,0]\n",
    "    ajuda[ajuda<0]=0\n",
    "    ajuda[ajuda>100]=100\n",
    "    a[:,:,0]=ajuda\n",
    "    saida=color.lab2rgb(a)\n",
    "    saida=saida*255\n",
    "    imgFt=Image.fromarray(np.uint8(saida))\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return imgFt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Um exemplo do que acontece com os histogramas da imagem quando se aplica o processo descrito acima pode ser visto nas imagens ilustrativas a seguir.</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"imagens/exemplos/fast_hist01.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imagens/exemplos/fast_hist02.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"imagens/exemplos/fast_hist03.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imagens/exemplos/fast_hist04.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p>Note que o histograma da imagem resultante mantém sua forma geral, porém ajusta sua altura e se desloca para que a distribuição \"se pareça mais\" com a da imagem de estilo.</p>\n",
    "\n",
    "#### Execute a célula abaixo para testar seu código\n",
    "\n",
    "<p>Execução pesada, pode levar um tempo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pares = []\n",
    "pares.append(['imagens/mar_salvador02.jpg', 'imagens/mar_salvador01.jpg'])\n",
    "pares.append(['imagens/capivara.jpg', 'imagens/grilo.jpg'])\n",
    "pares.append(['imagens/hindu.jpg', 'imagens/favela.jpg'])\n",
    "pares.append(['imagens/capivara_cinza.jpg', 'imagens/foto_antiga01.jpg'])\n",
    "for par in pares:\n",
    "    imgAlvo = abre_imagem(par[0])\n",
    "    imgEstilo = abre_imagem(par[1])\n",
    "    imgEspec = fast_transfer(imgAlvo, imgEstilo)\n",
    "    imgs = [imgAlvo,imgEstilo,imgEspec]\n",
    "    titulos = ['Imagem Alvo', 'Imagem com Estilo', 'Fast transfer']\n",
    "    exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 Comparação dos métodos\n",
    "\n",
    "<p>Execute a célula abaixo para comparar os resultados dos dois métodos e, logo após, responda às perguntas feitas.</p>\n",
    "\n",
    "<p>Este é o teste mais pesado que será feito em todo o trabalho. Portanto, pede-se que se tenha um pouco de paciência para aguardar a execução...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pares = []\n",
    "pares.append(['imagens/mar_salvador01.jpg', 'imagens/mar_salvador02.jpg'])\n",
    "pares.append(['imagens/mar_salvador02.jpg', 'imagens/mar_salvador01.jpg'])\n",
    "pares.append(['imagens/grilo.jpg', 'imagens/capivara.jpg'])\n",
    "pares.append(['imagens/capivara.jpg', 'imagens/grilo.jpg'])\n",
    "pares.append(['imagens/hindu.jpg', 'imagens/favela.jpg'])\n",
    "pares.append(['imagens/favela.jpg', 'imagens/hindu.jpg'])\n",
    "pares.append(['imagens/capivara_cinza.jpg', 'imagens/foto_antiga01.jpg'])\n",
    "pares.append(['imagens/capivara_cinza.jpg', 'imagens/foto_antiga02.jpg'])\n",
    "pares.append(['imagens/praia_cinza.png', 'imagens/foto_antiga03.png'])\n",
    "pares.append(['imagens/praia_cinza.png', 'imagens/foto_antiga04.png'])\n",
    "pares.append(['imagens/ufv_dia.jpg', 'imagens/ufv_noite.jpg'])\n",
    "pares.append(['imagens/ufv_noite.jpg', 'imagens/ufv_dia.jpg'])\n",
    "pares.append(['imagens/por_do_sol1.jpg', 'imagens/por_do_sol2.jpg'])\n",
    "pares.append(['imagens/por_do_sol2.jpg', 'imagens/por_do_sol1.jpg'])\n",
    "pares.append(['imagens/capivara.jpg', 'imagens/blue_tang.jpg'])\n",
    "pares.append(['imagens/grilo.jpg', 'imagens/blue_tang.jpg'])\n",
    "pares.append(['imagens/blue_tang.jpg', 'imagens/grilo.jpg'])\n",
    "pares.append(['imagens/papagaios.jpg', 'imagens/pimentas.png'])\n",
    "pares.append(['imagens/pimentas.png', 'imagens/papagaios.jpg'])\n",
    "pares.append(['imagens/lavoura.jpg', 'imagens/fitas_bonfim.jpg'])\n",
    "pares.append(['imagens/fitas_bonfim.jpg', 'imagens/lavoura.jpg'])\n",
    "pares.append(['imagens/pimentas.png', 'imagens/fitas_bonfim.jpg'])\n",
    "pares.append(['imagens/fitas_bonfim.jpg', 'imagens/pimentas.png'])\n",
    "for par in pares:\n",
    "    imgAlvo = abre_imagem(par[0])\n",
    "    imgEstilo = abre_imagem(par[1])\n",
    "    imgEspec = especificacao_direta(imgAlvo, imgEstilo)\n",
    "    imgTransf = fast_transfer(imgAlvo,imgEstilo)\n",
    "    imgs = [imgAlvo,imgEstilo,imgEspec, imgTransf]\n",
    "    titulos = ['Imagem Alvo', 'Imagem com Estilo', 'Especificação Direta', 'Fast Transfer']\n",
    "    exibe_bloco(imgs, titulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisando os resultados obtidos, responda as duas questões a seguir\n",
    "\n",
    "<p><b>5.3.3.1</b> Comparando os resultados de cada técnica para as várias situações acima, o que você pode dizer sobre a diferença visual entre as duas? Consegue identificar vantagens e desvantagens em cada técnica? Quais? (escreva sua resposta na célula a seguir)</p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A tecnica de fast transfer tende a fazer uma transferencia das cores melhor porém não lida bem com o brilho da imagem\n",
    "A tencina de especificação direta tende a realçar melhor os detalhes e deixar as cores mais vivas porém por vezes o brilho fica muito elevado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>5.3.3.2</b> Pode-se notar que em algumas situações ambas técnicas funcionam bem e em algumas ambas não funcionam tão bem. O que você acha que caracterizam essas situações? Por que? (escreva sua resposta na célula a seguir)</p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quando a imagem de estilo tem uma parte branco com um brilho alto,pois nesse tipo de imagem o brilho fica ainda maior na imagem resultado e por vezes até há cores destorcidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Ajuste de contraste usando o modelo YIQ\n",
    "\n",
    "<p>A ideia deste último exercício é fazer uma experiência com ajuste de contraste em imagens. Já vimos algumas técnicas, dentre elas o Alargamento de Contraste e a Equalização de Histogramas, ambas implementadas por você neste trabalho e aplicada ao modelo RGB.</p>\n",
    "\n",
    "<p>No entanto, vimos aqui um outro sistema de cores, o YIQ, que tem como característica, assim como o CIELAB, de ter um componente que representa apenas a informação de luminosidade. No caso, esta componente é a Y. Um teste que poderia ser feito, então, é manipular apenas esta componente de uma imagem, a fim de realçar contrastes de luminosidade e verificar o que acontece com o resultado.</p>\n",
    "\n",
    "<p>Poderíamos, portanto, aplicar o seguinte processo:</p>\n",
    "\n",
    "1. Converta uma imagem RGB para YIQ\n",
    "2. Aplique uma técnica de ajuste de contraste apenas na componente Y\n",
    "3. Converta o resultado de volta para RGB\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>equalizaY</code> abaixo, que recebe como parâmetro uma imagem de entrada, realiza o processo acima, aplicando a técnica de <b>Equalização de Histogramas</b> como o passo 2 e retorna o resultado.</p>\n",
    "\n",
    "<p><font color=\"red\">Implemente o corpo</font> da função <code>alargaY</code> abaixo, que recebe como parâmetro uma imagem de entrada, realiza o processo acima, aplicando a técnica de <b>Alargamento de Contraste</b> como o passo 2 e retorna o resultado.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalizaY(imgY):\n",
    "    imgYn=np.asarray(imgY)\n",
    "    fYn=rgb2yiq(imgYn)\n",
    "    CDFY = _histograma(np.round(fYn[:,:,0]),'cdf',256)\n",
    "    CDFY=255*CDFY\n",
    "    for X in range(fYn.shape[0]):\n",
    "        for Y in range(fYn.shape[1]):\n",
    "            pixel=fYn[X,Y,0]\n",
    "            pixel=CDFY[int(pixel)]\n",
    "            fYn[X,Y,0]=pixel\n",
    "    fYn=yiq2rgb(fYn)\n",
    "    fYn=Image.fromarray(np.uint8(np.round(fYn)))\n",
    "    return fYn\n",
    "\n",
    "def alargaY(img):\n",
    "    img=np.asarray(img)\n",
    "    f=rgb2yiq(img)\n",
    "    n=np.empty([f.shape[0],f.shape[1]])\n",
    "    n[:,:]=((f[:,:,0]-np.min(f[:,:,0]))/(np.max(f[:,:,0])-np.min(f[:,:,0])))*255\n",
    "    f[:,:,0]=n[:,:]\n",
    "    # Você pode alterar o retorno da função à vontade    \n",
    "    return Image.fromarray(np.uint8(yiq2rgb(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a célula abaixo para testar sua implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = []\n",
    "arquivos.append('imagens/praiaOrig.png')\n",
    "arquivos.append('imagens/praiaRuim.png')\n",
    "arquivos.append('imagens/praiaRuim2.png')\n",
    "arquivos.append('imagens/texto_1.jpg')\n",
    "arquivos.append('imagens/texto_2.jpg')\n",
    "arquivos.append('imagens/texto_sombra.jpg')\n",
    "arquivos.append('imagens/mar_salvador02.jpg')\n",
    "arquivos.append('imagens/ufv-estourada.jpg')\n",
    "arquivos.append('imagens/ufv_noite.jpg')\n",
    "arquivos.append('imagens/pousada-estourada.png')\n",
    "arquivos.append('imagens/capivara_cinza.jpg')\n",
    "arquivos.append('imagens/foto_antiga04.png')\n",
    "\n",
    "for i,arquivo in enumerate(arquivos):\n",
    "    img = abre_imagem(arquivo)\n",
    "    imgAlarg = alargaContraste(img)\n",
    "    imgEq = equaliza(img)\n",
    "    imgEqY = equalizaY(img)\n",
    "    imgAlargY = alargaY(img)\n",
    "    imgs = [img,\n",
    "            imgAlarg,\n",
    "            imgEq,\n",
    "            imgAlargY,\n",
    "            imgEqY\n",
    "            ]\n",
    "    titulos = ['Original',\n",
    "               'Alargamento em RGB',\n",
    "               'Equalização em RGB',\n",
    "               'Alargamento em Y apenas',\n",
    "               'Equalização em Y apenas'\n",
    "              ]\n",
    "    exibe_bloco(imgs, titulos, tam_linha=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais\n",
    "\n",
    "- Salve seu Notebook e envie, pelo Moodle, apenas ele.\n",
    "- Releia as observações no início do enunciado para checar se não se esqueceu de nenhum item\n",
    "- Confira seus resultados com os exemplos fornecidos, mas também faça testes criados por você\n",
    "\n",
    "<p style=\"text-align: right\">Bons estudos,</p>\n",
    "<p style=\"text-align: right\">Prof. Marcos</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
